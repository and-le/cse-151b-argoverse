{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0+cu92'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File system\n",
    "import os, os.path \n",
    "import pickle\n",
    "from glob import glob\n",
    "import sys\n",
    "\n",
    "# Workflow\n",
    "import random\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "\n",
    "# Computation\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Data visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(rc={\"figure.dpi\":100, 'savefig.dpi':100})\n",
    "sns.set_context('notebook')\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys to the pickle objects\n",
    "CITY = 'city'\n",
    "LANE = 'lane'\n",
    "LANE_NORM = 'lane_norm'\n",
    "SCENE_IDX = 'scene_idx'\n",
    "AGENT_ID = 'agent_id'\n",
    "P_IN = 'p_in'\n",
    "V_IN = 'v_in'\n",
    "P_OUT = 'p_out'\n",
    "V_OUT = 'v_out'\n",
    "CAR_MASK = 'car_mask'\n",
    "TRACK_ID = 'track_id'\n",
    "\n",
    "# Encode Miami as 0, Pittsburgh as 1\n",
    "MIA = 'MIA'\n",
    "PIT = 'PIT'  \n",
    "CITY_MAP = {MIA: 0, PIT: 1}\n",
    "\n",
    "# Transformed data keys\n",
    "LANE_IN = 'closest_lanes_in'\n",
    "NORM_IN = 'closest_lane_norms_in'\n",
    "LANE_OUT = 'closest_lanes_out'\n",
    "NORM_OUT = 'closest_lane_norms_out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset variables\n",
    "VALIDATION_PATH = './val_data/'\n",
    "ORIGINAL_PATH = './original_train_data/'\n",
    "TRANSFORMED_TRAIN_PATH = './transformed_train_data'\n",
    "TRANSFORMED_VAL_PATH = './transformed_val_data'\n",
    "\n",
    "\n",
    "train_path = TRANSFORMED_TRAIN_PATH\n",
    "val_path = TRANSFORMED_VAL_PATH\n",
    "\n",
    "# Path to model predictions on test set\n",
    "PREDICTION_PATH = './my_submission.csv'\n",
    "# Header of predictions CSV file\n",
    "CSV_HEADER = ['ID,'] + ['v' + str(i) + ',' for i in range(1, 60)] + ['v60', '\\n']\n",
    "\n",
    "# Get list of all training file names\n",
    "original_files = glob(os.path.join(train_path, '*'))\n",
    "\n",
    "# 80-20 train-test split\n",
    "train_files = random.sample(original_files, int(len(original_files) * 0.8))\n",
    "test_files = list(set(original_files) - set(train_files))\n",
    "\n",
    "# Validation\n",
    "val_files = glob(os.path.join(val_path, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Control variables\n",
    "USE_ONE_AGENT = True\n",
    "PREDICT_ONE_AGENT = True  # controls whether 60-agent inputs are mapped to just the target agent's outputs\n",
    "\n",
    "NUM_AGENTS = 1 if USE_ONE_AGENT else 60\n",
    "IN_LEN = 19\n",
    "OUT_LEN = 30\n",
    "\n",
    "# Controls how many features to use\n",
    "N_FEAT_IN = 4\n",
    "N_FEAT_OUT = 2\n",
    "\n",
    "# Batch variables\n",
    "BATCH_SIZE_TRAIN = 64\n",
    "BATCH_SIZE_TEST = BATCH_SIZE_TRAIN\n",
    "BATCH_SIZE_VAL = 32\n",
    "N_WORKERS = 4\n",
    "# Windows doesn't support anything but N_WORKERS = 0 for the DataLoader\n",
    "if 'win' in sys.platform:\n",
    "    N_WORKERS = 0\n",
    "N_WORKERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.files = files\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.files[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_train_test(batch):\n",
    "    \"\"\" \n",
    "    Custom collate_fn function to be used for DataLoader.    \n",
    "    The input tensor is organized as 19 rows, where each row has 4 columns: px, py, vx, vy\n",
    "    \n",
    "    The output tensor can be organized in 2 ways:\n",
    "    A) The output tensor is organized as 120 rows, where each row has 1 column. \n",
    "    Each contiguous sequence of 4 elements is px, py, vx, vy\n",
    "    \n",
    "    B) The input tensor is organized as 30 rows, where each row has 4 columns: px, py, vx, vy\n",
    "    \"\"\"    \n",
    "    inp = []        \n",
    "    out = []\n",
    "    agent_idxs = []\n",
    "    scene_idxs = []\n",
    "    city_ids = []\n",
    "    for scene in batch:\n",
    "        # Get the target agent id\n",
    "        agent_id = scene[AGENT_ID]        \n",
    "        # Get the matrix of all agents\n",
    "        track_id = scene[TRACK_ID]        \n",
    "        # Get the location of the target agent in the matrix\n",
    "        idx = np.nonzero(track_id[:, 0] == agent_id)[0][0]\n",
    "        \n",
    "        # Number of time steps in the input and output sequences\n",
    "        inlen = scene[P_IN].shape[1]\n",
    "        outlen = scene[P_OUT].shape[1]\n",
    "        \n",
    "        # Aliases of scene variables for convenience\n",
    "        pin, pout, vin, vout = scene[P_IN], scene[P_OUT], scene[V_IN], scene[V_OUT]\n",
    "        lanein, laneout, normin, normout = scene[LANE_IN], scene[LANE_OUT], scene[NORM_IN], scene[NORM_OUT]\n",
    "        \n",
    "        # Use these lines to include only the target agent.\n",
    "        # Training with just one agent is faster and preferred for experimentation\n",
    "        if USE_ONE_AGENT:  \n",
    "            if scene[CITY] == MIA:\n",
    "                cities = np.zeros((inlen, 1)) \n",
    "            else:\n",
    "                cities = np.ones((inlen, 1)) \n",
    "\n",
    "            # Use this line to include all input features\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], lanein[idx], normin[idx], cities), axis=1)    \n",
    "\n",
    "            # Lane and norm only\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], lanein[idx], normin[idx]), axis=1) \n",
    "\n",
    "            # Lane  only\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], lanein[idx]), axis=1) \n",
    "\n",
    "            # Only include cities\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], cities), axis=1)     \n",
    "\n",
    "            # Only include pos/vel\n",
    "            inp_tens = np.concatenate((pin[idx], vin[idx]), axis=1)\n",
    "\n",
    "            # All output features\n",
    "#             out_tens = np.concatenate((pout[idx], vout[idx], laneout[idx], normout[idx]), axis=1)\n",
    "            # Only include output position and velocity\n",
    "            out_tens = np.concatenate((pout[idx], vout[idx]), axis=1)   \n",
    "        \n",
    "#             out_tens = pout[idx]\n",
    "            \n",
    "        # Use these lines to include all 60 agents, even the dummy agents.\n",
    "        # Training with all 60 agents is much slower than with just one agent.\n",
    "        else:\n",
    "            num_agents = pin.shape[0]\n",
    "            if scene[CITY] == MIA:\n",
    "                cities = np.zeros((num_agents, inlen, 1)) \n",
    "            else:\n",
    "                cities = np.ones((num_agents, inlen, 1))  \n",
    "                \n",
    "            # Include all features\n",
    "#             inp_tens = np.concatenate((pin, vin, lanein, normin, cities), axis=2)  \n",
    "            # Lane only\n",
    "#             inp_tens = np.concatenate((pin, vin, lanein, normin), axis=2)   \n",
    "            # Include only cities\n",
    "            inp_tens = np.concatenate((pin, vin, cities), axis=2) \n",
    "            # Include only pos/vel\n",
    "#             inp_tens = np.concatenate((pin, vin), axis=2)\n",
    "            \n",
    "            # Makes predictions for only the target agent\n",
    "            if PREDICT_ONE_AGENT:\n",
    "                # All features\n",
    "#                 out_tens = np.concatenate((pout[idx], vout[idx], laneout[idx], normout[idx]), axis=1)                \n",
    "                # Pos/vel\n",
    "                out_tens = np.concatenate((pout[idx], vout[idx]), axis=1)\n",
    "\n",
    "            # Makes predictions for all 60 agents\n",
    "            else:\n",
    "                # All features\n",
    "#                 out_tens = np.concatenate((pout, vout, laneout, normout), axis=2)                \n",
    "                # pv\n",
    "                out_tens = np.concatenate((pout, vout), axis=2) \n",
    "        \n",
    "        inp.append(inp_tens)\n",
    "        out.append(out_tens)        \n",
    "        scene_idxs.append(scene[SCENE_IDX]) \n",
    "        agent_idxs.append(idx)\n",
    "        city_ids.append(CITY_MAP[scene[CITY]])\n",
    "\n",
    "    inp = torch.FloatTensor(inp)\n",
    "    out = torch.FloatTensor(out)\n",
    "    return [inp, out, scene_idxs, agent_idxs, city_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_val(batch):\n",
    "    \"\"\" \n",
    "    Custom collate_fn for validation dataset. The validation data do not contain output values.   \n",
    "    The input tensor is organized as 19 rows, where each row has 4 columns: px, py, vx, vy\n",
    "    \"\"\"   \n",
    "    inp = []\n",
    "    scene_idxs = []\n",
    "    agent_idxs = []\n",
    "    city_ids = []\n",
    "    \n",
    "    for scene in batch:\n",
    "        # Get the target agent id\n",
    "        agent_id = scene[AGENT_ID]        \n",
    "        # Get the matrix of all agents\n",
    "        track_id = scene[TRACK_ID]        \n",
    "        # Get the location of the target agent in the matrix\n",
    "        idx = np.nonzero(track_id[:, 0] == agent_id)[0][0]\n",
    "        \n",
    "        inlen = scene[P_IN].shape[1]\n",
    "        \n",
    "        # Aliases of scene variables for convenience\n",
    "        pin, vin = scene[P_IN], scene[V_IN]\n",
    "        lanein, normin = scene[LANE_IN], scene[NORM_IN]\n",
    "        num_agents = scene[P_IN].shape[0]\n",
    "        \n",
    "        # Use these lines to include only the target agent.\n",
    "        if USE_ONE_AGENT:\n",
    "            if scene[CITY] == MIA:\n",
    "                cities = np.zeros((inlen, 1)) \n",
    "            else:\n",
    "                cities = np.ones((inlen, 1)) \n",
    "            # All\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], lanein[idx], normin[idx], cities), axis=1)\n",
    "            # Lane and norm only\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], lanein[idx], normin[idx]), axis=1)\n",
    "\n",
    "            # Lane  only\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], lanein[idx]), axis=1) \n",
    "        \n",
    "            # Cities\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], cities), axis=1)  \n",
    "            # Pos/vel\n",
    "            inp_tens = np.concatenate((pin[idx], vin[idx]), axis=1)  \n",
    "\n",
    "        # Use these lines to include all 60 agents\n",
    "        else:\n",
    "            if scene[CITY] == MIA:\n",
    "                cities = np.zeros((num_agents, inlen, 1)) \n",
    "            else:\n",
    "                cities = np.ones((num_agents, inlen, 1))\n",
    "            # All features\n",
    "#             inp_tens = np.concatenate( (pin, vin, lanein, normin, cities), axis=2)       \n",
    "            # Lane only\n",
    "#             inp_tens = np.concatenate( (pin, vin, lanein, normin), axis=2)\n",
    "            # Cities\n",
    "            inp_tens = np.concatenate( (pin, vin, cities), axis=2)             \n",
    "            # pv\n",
    "#             inp_tens = np.concatenate( (pin, vin), axis=2)  \n",
    "        \n",
    "        inp.append(inp_tens)        \n",
    "        scene_idxs.append(scene[SCENE_IDX])\n",
    "        agent_idxs.append(idx)\n",
    "        city_ids.append(CITY_MAP[scene[CITY]])        \n",
    "        \n",
    "    inp = torch.FloatTensor(inp)    \n",
    "    return [inp, scene_idxs, agent_idxs, city_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliaze datasets and loaders\n",
    "\n",
    "train_dataset = ArgoverseDataset(train_files)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, \n",
    "                                           shuffle=True, collate_fn=collate_train_test, \n",
    "                                           num_workers=N_WORKERS)\n",
    "test_dataset = ArgoverseDataset(test_files)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, \n",
    "                                          shuffle=False, collate_fn=collate_train_test, \n",
    "                                          num_workers=N_WORKERS)\n",
    "val_dataset = ArgoverseDataset(val_files)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE_VAL, \n",
    "                                         shuffle=False, collate_fn=collate_val,\n",
    "                                         num_workers=N_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 19, 4])\n",
      "torch.Size([64, 30, 4])\n",
      "torch.Size([64, 19, 2])\n",
      "torch.Size([64, 19, 6])\n"
     ]
    }
   ],
   "source": [
    "# Look at one data sample      \n",
    "for _, (data, target, agent_idxs, scene_idxs, cities) in enumerate(train_loader):\n",
    "    print(data.shape)\n",
    "    print(target.shape) \n",
    "    \n",
    "    temp = data[:, :, :2]\n",
    "    print(temp.shape)\n",
    "    cat = torch.cat((data, temp), dim=2)\n",
    "    print(cat.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 19, 4])\n"
     ]
    }
   ],
   "source": [
    "# Look at one data sample      \n",
    "for _, (data, agent_idxs, scene_idxs, masks) in enumerate(val_loader):\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model1, model2, device, train_loader, test_loader, optimizer1, optimizer2, epoch):\n",
    "    model1.train()  \n",
    "    model2.train()\n",
    "    model.train()\n",
    "\n",
    "    criterion1 = torch.nn.MSELoss(reduction='mean')\n",
    "    criterion2 = torch.nn.MSELoss(reduction='mean')\n",
    "    criterion3 = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "    total_loss1 = total_loss2 = total_loss3 = 0    \n",
    "    for i in range(epoch):\n",
    "\n",
    "        iterator = tqdm.notebook.tqdm(train_loader, total=int(len(train_loader)))\n",
    "        for _, batch in enumerate(iterator):\n",
    "            data, target, scene_idxs, agent_idxs, cities = batch\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer1.zero_grad()      \n",
    "            optimizer2.zero_grad()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            out1 = model1(data) \n",
    "            out2 = model2(data)            \n",
    "            \n",
    "            temp1 = torch.clone(out1.detach())\n",
    "            temp2 = torch.clone(out2.detach())\n",
    "            out3 = model(torch.cat((temp1, temp2), dim=2))\n",
    "            \n",
    "            loss1 = torch.sqrt(criterion1(out1, target[:, :, :2]))     \n",
    "            loss2 = torch.sqrt(criterion2(out2, target[:, :, 2:4]))\n",
    "            loss3 = torch.sqrt(criterion3(out3, target[:, :, :2])) \n",
    "            \n",
    "            total_loss1 += loss1.item()\n",
    "            total_loss2 += loss2.item()\n",
    "            total_loss3 += loss3.item()\n",
    "\n",
    "            loss1.backward()\n",
    "            loss2.backward()\n",
    "            loss3.backward()\n",
    "            \n",
    "            optimizer1.step()\n",
    "            optimizer2.step()\n",
    "            opt.step()\n",
    "\n",
    "\n",
    "            # Update the progress bar for tqdm\n",
    "            iterator.set_postfix(train_loss_vel=loss1.item(), train_loss_pos=loss2.item(), train_loss_final=loss3.item())\n",
    "            \n",
    "    return (total_loss1 * BATCH_SIZE_TRAIN) / len(train_files), (total_loss2 * BATCH_SIZE_TRAIN) / len(train_files), (total_loss3 * BATCH_SIZE_TRAIN) / len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model1, model2, device, test_loader):\n",
    "    model1.eval()  \n",
    "    model2.eval()\n",
    "    model.eval()\n",
    "\n",
    "    criterion1 = torch.nn.MSELoss(reduction='mean')    \n",
    "    criterion2 = torch.nn.MSELoss(reduction='mean')    \n",
    "    criterion3 = torch.nn.MSELoss(reduction='mean')    \n",
    "\n",
    "    iterator = tqdm.notebook.tqdm(test_loader, total=int(len(test_loader)))\n",
    "    total_loss1 = total_loss2 = total_loss3 = 0\n",
    "    \n",
    "    for _, batch in enumerate(iterator):\n",
    "        data, target, scene_idxs, agent_idxs, masks = batch\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            out1 = model1(data) \n",
    "            out2 = model2(data)            \n",
    "            \n",
    "            temp1 = torch.clone(out1.detach())\n",
    "            temp2 = torch.clone(out2.detach())\n",
    "            out3 = model(torch.cat((temp1, temp2), dim=2))\n",
    "            \n",
    "            loss1 = torch.sqrt(criterion1(out1, target[:, :, :2]))     \n",
    "            loss2 = torch.sqrt(criterion2(out2, target[:, :, 2:4]))\n",
    "            loss3 = torch.sqrt(criterion3(out3, target[:, :, :2]))        \n",
    "\n",
    "\n",
    "            total_loss1 += loss1.item()\n",
    "            total_loss2 += loss2.item()\n",
    "            total_loss3 += loss3.item()\n",
    "\n",
    "                \n",
    "            iterator.set_postfix(test_los_vel=loss1.item(), test_loss_pos=loss2.item(), test_loss_final=loss3.item())\n",
    "        \n",
    "    return (total_loss1 * BATCH_SIZE_TEST) / len(test_files), (total_loss2 * BATCH_SIZE_TEST) / len(test_files), (total_loss3 * BATCH_SIZE_TEST) / len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model1, model2, DEVICE, train_loader, test_loader, optimizer1, optimizer2, NUM_EPOCH):\n",
    "    for t in range(1, NUM_EPOCH + 1):\n",
    "        train_loss = train(model1, model2, DEVICE, train_loader, test_loader, optimizer1, optimizer2, 1)\n",
    "        test_loss = test(model1, model2, DEVICE, test_loader)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        print(f'Epoch {t}')\n",
    "        print(f'vel train_loss = {train_loss[0]}, pos train = {train_loss[1]}')\n",
    "        print(f'vel test_loss = {test_loss[0]}, pos test_loss = {test_loss[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, val_loader, path):\n",
    "    \"\"\"\n",
    "    path: path to csv file to write predictions\n",
    "    \"\"\"\n",
    "    model.eval()   \n",
    "    \n",
    "    # Prep the output file\n",
    "    with open(PREDICTION_PATH, \"w\") as csv_file:\n",
    "        # Clear the csv file before appending data to it\n",
    "        csv_file.truncate()\n",
    "        # Write the header to the csv file\n",
    "        csv_file.writelines(CSV_HEADER)    \n",
    "    \n",
    "    # Make predictions\n",
    "    with open(path, \"a\") as pred_file:        \n",
    "        iterator = tqdm.notebook.tqdm(val_loader, total=int(len(val_loader)))\n",
    "        \n",
    "        for _, batch in enumerate(iterator):\n",
    "            data, scene_idxs, agent_idxs, cities = batch\n",
    "            data = data.to(device) \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "                # Convert the Tensor from GPU -> CPU -> NumPy array\n",
    "                np_out = output.cpu().detach().numpy()\n",
    "                \n",
    "                # Store only the predictions for the target agent and keep the positions, not the velocities\n",
    "                batch_size = np_out.shape[0]\n",
    "                \n",
    "                pred = np.zeros((batch_size, 60))\n",
    "                if PREDICT_ONE_AGENT:\n",
    "                    # The output should be a (batch size, time steps, num features out) tensor \n",
    "                    # where the first two features are the out position x, y\n",
    "                    for i in range(batch_size):\n",
    "                        pred[i] = np_out[i, :, :2].flatten()\n",
    "                else:\n",
    "                    # The output should be a (batch size, num agents, time steps, num features out) tensor \n",
    "                    # where the first two features are the input position and the output position\n",
    "                    for i in range(batch_size):\n",
    "                        idx = agent_idxs[i]\n",
    "                        pred[i] = np_out[i, idx, :, :2].flatten()                    \n",
    "\n",
    "                # Form comma-separated string\n",
    "                s = []\n",
    "                for i in range(pred.shape[0]):\n",
    "                    s.append(','.join([str(scene_idxs[i])] + [str(v) for v in pred[i]]) + '\\n')\n",
    "\n",
    "                # Write data to file\n",
    "                pred_file.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PosNet(torch.nn.Module):\n",
    "#     \"\"\"\n",
    "#     Neural Network class - linear regression\n",
    "#     \"\"\"\n",
    "#     def __init__(self, device):\n",
    "#         super(PosNet, self).__init__() \n",
    "        \n",
    "#         self.device = device        \n",
    "#         # Linear regression for 1 agent     \n",
    "#         if PREDICT_ONE_AGENT:\n",
    "#             self.fc = nn.Linear(NUM_AGENTS * IN_LEN * N_FEAT_IN, 1 * OUT_LEN * N_FEAT_OUT)\n",
    "#             self.fc2 = nn.Linear(1 * OUT_LEN * (N_FEAT_OUT + 2), 1 * OUT_LEN * N_FEAT_OUT)\n",
    "#         else:\n",
    "#             self.fc = nn.Linear(NUM_AGENTS * IN_LEN * N_FEAT_IN, NUM_AGENTS * OUT_LEN * N_FEAT_OUT)\n",
    "    \n",
    "#     def forward(self, x, extra):\n",
    "#         x = x.view(x.size(0), -1)  # flatten result\n",
    "#         x = self.fc(x)   \n",
    "#         x = torch.cat((x.view(x.shape[0], OUT_LEN, 2), extra), dim=2)\n",
    "#         x = x.view(x.shape[0], -1)\n",
    "#         x = nn.functional.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         if PREDICT_ONE_AGENT:\n",
    "#             x = x.view(x.size(0), OUT_LEN, N_FEAT_OUT)\n",
    "#         else:\n",
    "#             x = x.view(x.size(0), NUM_AGENTS, OUT_LEN, N_FEAT_OUT)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class INet(torch.nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(INet, self).__init__() \n",
    "\n",
    "        self.device = device        \n",
    "        # Linear regression for 1 agent     \n",
    "        if PREDICT_ONE_AGENT:\n",
    "            self.fc = nn.Linear(NUM_AGENTS * IN_LEN * N_FEAT_IN, 1 * OUT_LEN * N_FEAT_OUT)\n",
    "        else:\n",
    "            self.fc = nn.Linear(NUM_AGENTS * IN_LEN * N_FEAT_IN, NUM_AGENTS * OUT_LEN * N_FEAT_OUT)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # flatten result\n",
    "        x = self.fc(x)            \n",
    "        if PREDICT_ONE_AGENT:\n",
    "            x = x.view(x.size(0), OUT_LEN, N_FEAT_OUT)\n",
    "        else:\n",
    "            x = x.view(x.size(0), NUM_AGENTS, OUT_LEN, N_FEAT_OUT)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoNet(torch.nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(ArgoNet, self).__init__() \n",
    "\n",
    "        self.device = device        \n",
    "        # Linear regression for 1 agent     \n",
    "        if PREDICT_ONE_AGENT:\n",
    "            self.fc = nn.Linear(NUM_AGENTS * OUT_LEN * N_FEAT_IN, 1 * OUT_LEN * N_FEAT_OUT)\n",
    "        else:\n",
    "            self.fc = nn.Linear(NUM_AGENTS * IN_LEN * N_FEAT_IN, NUM_AGENTS * OUT_LEN * N_FEAT_OUT)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # flatten result\n",
    "        x = self.fc(x)            \n",
    "        if PREDICT_ONE_AGENT:\n",
    "            x = x.view(x.size(0), OUT_LEN, N_FEAT_OUT)\n",
    "        else:\n",
    "            x = x.view(x.size(0), NUM_AGENTS, OUT_LEN, N_FEAT_OUT)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to save and reload a model\n",
    "MODEL_STATE = 'model_state_dict'\n",
    "OPTIMIZER_STATE = 'optimizer_state_dict'\n",
    "EPOCH_STATE = 'epoch'\n",
    "LOSS_STATE = 'loss'\n",
    "BATCH_STATE = 'batch'\n",
    "\n",
    "def save_model(path, model_state_dict, optimizer_state_dict, epoch, loss, batch):\n",
    "    to_save = {\n",
    "        MODEL_STATE: model_state_dict,\n",
    "        OPTIMIZER_STATE: optimizer_state_dict,\n",
    "        EPOCH_STATE: epoch,\n",
    "        LOSS_STATE: loss,\n",
    "        BATCH_STATE: batch\n",
    "    }\n",
    "    torch.save(to_save, path)\n",
    "    \n",
    "def load_model(path, model_to_load, optimizer_to_load):\n",
    "    checkpoint = torch.load(path)\n",
    "    model_to_load.load_state_dict(checkpoint[MODEL_STATE])\n",
    "    optimizer_to_load.load_state_dict(checkpoint[OPTIMIZER_STATE])\n",
    "    return checkpoint[EPOCH_STATE], checkpoint[LOSS_STATE], checkpoint[BATCH_STATE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posmodel parameters is 4620\n",
      "Number of velmodel parameters is 4620\n",
      "Number of final model parameters is 7260\n"
     ]
    }
   ],
   "source": [
    "posmodel = INet(DEVICE).to(DEVICE)\n",
    "velmodel = INet(DEVICE).to(DEVICE)\n",
    "posopt = torch.optim.Adam(posmodel.parameters())\n",
    "velopt = torch.optim.Adam(velmodel.parameters())\n",
    "\n",
    "# learning_rate = 1e-1\n",
    "# momentum = 0.9\n",
    "# weight_decay = 1\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "print(f\"Number of posmodel parameters is {sum(p.numel() for p in posmodel.parameters())}\")\n",
    "print(f\"Number of velmodel parameters is {sum(p.numel() for p in velmodel.parameters())}\")\n",
    "model = ArgoNet(DEVICE).to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "print(f\"Number of final model parameters is {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "NUM_EPOCH = 3\n",
    "\n",
    "# used for visualizing the loss\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these two lines to save a model\n",
    "# save_model('two_hid_one_agent_ep6.tar', model.state_dict(), optimizer.state_dict(), NUM_EPOCH, \n",
    "#            (train_losses[-1], test_losses[-1]), BATCH_SIZE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload a model\n",
    "# model = ArgoNet(DEVICE).to(DEVICE)\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "# load_model('one_hid_one_agent.tar', model, optimizer)\n",
    "# train_losses.clear()\n",
    "# test_losses.clear()\n",
    "# num_params = sum(p.numel() for p in model.parameters())   \n",
    "# print(f\"Number of model parameters is {num_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febba4060fb44cbb9479b95ea9c39065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2575.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a27de93ed946b49f20e26eb22c443c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=644.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa0b60c47a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "vel train_loss = 31.15187471688724, pos train = 10.380715968611707\n",
      "vel test_loss = 4.031332291287713, pos test_loss = 6.350796831013315\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526b6be8a389463ba9680831a3a900a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2575.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-471234aa7894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvelmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvelopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-9a89c2c5082c>\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m(model1, model2, DEVICE, train_loader, test_loader, optimizer1, optimizer2, NUM_EPOCH)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-019acf04b404>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model1, model2, device, train_loader, test_loader, optimizer1, optimizer2, epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscene_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_test(velmodel, posmodel, DEVICE, train_loader, test_loader, velopt, posopt, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653cdc6022ce4ad29057e56998e618e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validate(model, DEVICE, val_loader, PREDICTION_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(losses):\n",
    "    \"\"\"\n",
    "    Plots the losses over each training iteration. \n",
    "    Assumes that each element of the 'losses' list corresponds to the loss after each batch of train()\n",
    "    \"\"\"\n",
    "    t_iter = np.arange(1, len(losses) + 1, 1, dtype=int)\n",
    "    ax = sns.scatterplot(x=t_iter, y=losses, alpha=0.5)    \n",
    "    ax.set_xlabel('Batch iteration number')\n",
    "    ax.set_ylabel('Root-mean-square loss')\n",
    "    ax.set_title('Batch Iteration vs. Root-Mean-Square Loss')\n",
    "    plt.savefig('lossViter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_loss(train_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, device, loader):\n",
    "    \"\"\"\n",
    "    Compares some randomly selected data samples to the model's predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of data\n",
    "    _, (inp, out, scene_idxs, agent_idxs, masks) = next(enumerate(loader))\n",
    "    \n",
    "    # Move tensors to chosen device\n",
    "    inp, out = inp.to(device), out.to(device)\n",
    "    \n",
    "    # Sample number\n",
    "    i = 0\n",
    "    \n",
    "    # Scene idx\n",
    "    scene_idx = scene_idxs[i]\n",
    "        \n",
    "    # Get contiguous arrays of the ground truth output positions\n",
    "    truth = target[i].cpu().detach().numpy()\n",
    "    x = truth[:, 0]\n",
    "    y = truth[:, 1] \n",
    "        \n",
    "    # Get contiguous arrays of the prediction output positions\n",
    "    output = model(inp)    \n",
    "    pred = output[i].cpu().detach().numpy()\n",
    "    xh = pred[:, 0]\n",
    "    yh = pred[:, 0]    \n",
    "    \n",
    "    # Plot the ground truth and prediction positions\n",
    "    fig, (ax) = plt.subplots(nrows=1, ncols=1, figsize=(3, 3))\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_title('Scene ' + str(scene_idx))\n",
    "    ax.scatter(x, y, label='Ground Truth')\n",
    "    ax.scatter(xh, yh, label='Prediction')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(model, DEVICE, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
