{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0+cu111'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File system\n",
    "import os, os.path \n",
    "import pickle\n",
    "from glob import glob\n",
    "import sys\n",
    "\n",
    "# Workflow\n",
    "import random\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "\n",
    "# Computation\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Data visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(rc={\"figure.dpi\":100, 'savefig.dpi':100})\n",
    "sns.set_context('notebook')\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys to the pickle objects\n",
    "CITY = 'city'\n",
    "LANE = 'lane'\n",
    "LANE_NORM = 'lane_norm'\n",
    "SCENE_IDX = 'scene_idx'\n",
    "AGENT_ID = 'agent_id'\n",
    "P_IN = 'p_in'\n",
    "V_IN = 'v_in'\n",
    "P_OUT = 'p_out'\n",
    "V_OUT = 'v_out'\n",
    "CAR_MASK = 'car_mask'\n",
    "TRACK_ID = 'track_id'\n",
    "\n",
    "# Encode Miami as 0, Pittsburgh as 1\n",
    "MIA = 'MIA'\n",
    "PIT = 'PIT'  \n",
    "CITY_MAP = {MIA: 0, PIT: 1}\n",
    "\n",
    "# Transformed data keys\n",
    "LANE_IN = 'closest_lanes_in'\n",
    "NORM_IN = 'closest_lane_norms_in'\n",
    "LANE_OUT = 'closest_lanes_out'\n",
    "NORM_OUT = 'closest_lane_norms_out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset variables\n",
    "VALIDATION_PATH = './val_data/'\n",
    "ORIGINAL_PATH = './original_train_data/'\n",
    "TRANSFORMED_TRAIN_PATH = './transformed_train_data'\n",
    "TRANSFORMED_VAL_PATH = './transformed_val_data'\n",
    "\n",
    "train_path = TRANSFORMED_TRAIN_PATH\n",
    "val_path = TRANSFORMED_VAL_PATH\n",
    "\n",
    "# Path to model predictions on test set\n",
    "PREDICTION_PATH = './my_submission.csv'\n",
    "# Header of predictions CSV file\n",
    "CSV_HEADER = ['ID,'] + ['v' + str(i) + ',' for i in range(1, 60)] + ['v60', '\\n']\n",
    "\n",
    "# Get list of all training file names\n",
    "original_files = glob(os.path.join(train_path, '*'))\n",
    "\n",
    "# 80-20 train-test split\n",
    "train_files = random.sample(original_files, int(len(original_files) * 0.8))\n",
    "test_files = list(set(original_files) - set(train_files))\n",
    "\n",
    "# Validation\n",
    "val_files = glob(os.path.join(val_path, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_AGENTS = 1\n",
    "IN_LEN = 19\n",
    "OUT_LEN = 30\n",
    "\n",
    "# Controls how many features to use\n",
    "N_FEAT_IN = 4\n",
    "N_FEAT_OUT = 2\n",
    "\n",
    "# Batch variables\n",
    "BATCH_SIZE_TRAIN = 64\n",
    "BATCH_SIZE_TEST = BATCH_SIZE_TRAIN\n",
    "BATCH_SIZE_VAL = 32\n",
    "N_WORKERS = 4\n",
    "# Windows doesn't support anything but N_WORKERS = 0 for the DataLoader\n",
    "if 'win' in sys.platform:\n",
    "    N_WORKERS = 0\n",
    "N_WORKERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.files = files\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.files[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_train_test(batch):\n",
    "    \"\"\" \n",
    "    Custom collate_fn function to be used for DataLoader.    \n",
    "    The input tensor is organized as 19 rows, where each row has 4 columns: px, py, vx, vy\n",
    "    \n",
    "    The output tensor can be organized in 2 ways:\n",
    "    A) The output tensor is organized as 120 rows, where each row has 1 column. \n",
    "    Each contiguous sequence of 4 elements is px, py, vx, vy\n",
    "    \n",
    "    B) The input tensor is organized as 30 rows, where each row has 4 columns: px, py, vx, vy\n",
    "    \"\"\"    \n",
    "    inp = []     \n",
    "    vel = []\n",
    "    out = []\n",
    "    agent_idxs = []\n",
    "    scene_idxs = []\n",
    "    for num, scene in enumerate(batch):\n",
    "        # Get the target agent id\n",
    "        agent_id = scene[AGENT_ID]        \n",
    "        # Get the matrix of all agents\n",
    "        track_id = scene[TRACK_ID]        \n",
    "        # Get the location of the target agent in the matrix\n",
    "        idx = np.nonzero(track_id[:, 0] == agent_id)[0][0]\n",
    "        \n",
    "        # Aliases of scene variables for convenience\n",
    "        pin, pout, vin, vout = scene[P_IN], scene[P_OUT], scene[V_IN], scene[V_OUT]\n",
    "\n",
    "        # Only include pos/vel\n",
    "        inp_tens = np.concatenate((pin[idx], vin[idx]), axis=1)        \n",
    "        out_tens = pout[idx] \n",
    "        \n",
    "        inp.append(inp_tens)\n",
    "        out.append(out_tens)  \n",
    "        vel.append(vout[idx])\n",
    "\n",
    "#         scene_idxs.append(scene[SCENE_IDX]) \n",
    "#         agent_idxs.append(idx)\n",
    "\n",
    "\n",
    "    inp = torch.FloatTensor(inp)\n",
    "    out = torch.FloatTensor(out)\n",
    "    vel = torch.FloatTensor(vel)\n",
    "    return [inp, out, scene_idxs, agent_idxs, vel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_val(batch):\n",
    "    \"\"\" \n",
    "    Custom collate_fn for validation dataset. The validation data do not contain output values.   \n",
    "    The input tensor is organized as 19 rows, where each row has 4 columns: px, py, vx, vy\n",
    "    \"\"\"   \n",
    "    inp = []\n",
    "    scene_idxs = []\n",
    "    agent_idxs = []\n",
    "    \n",
    "    for num, scene in enumerate(batch):\n",
    "        # Get the target agent id\n",
    "        agent_id = scene[AGENT_ID]        \n",
    "        # Get the matrix of all agents\n",
    "        track_id = scene[TRACK_ID]        \n",
    "        # Get the location of the target agent in the matrix\n",
    "        idx = np.nonzero(track_id[:, 0] == agent_id)[0][0]\n",
    "                \n",
    "        # Aliases of scene variables for convenience\n",
    "        pin, vin = scene[P_IN], scene[V_IN]       \n",
    "        inp_tens = np.concatenate((pin[idx], vin[idx]), axis=1)\n",
    "        \n",
    "        inp.append(inp_tens)        \n",
    "        scene_idxs.append(scene[SCENE_IDX])\n",
    "        agent_idxs.append(idx)\n",
    "        \n",
    "    inp = torch.FloatTensor(inp)    \n",
    "    return [inp, scene_idxs, agent_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliaze datasets and loaders\n",
    "train_dataset = ArgoverseDataset(train_files)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, \n",
    "                                           shuffle=True, collate_fn=collate_train_test, \n",
    "                                           num_workers=N_WORKERS)\n",
    "test_dataset = ArgoverseDataset(test_files)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, \n",
    "                                          shuffle=False, collate_fn=collate_train_test, \n",
    "                                          num_workers=N_WORKERS)\n",
    "val_dataset = ArgoverseDataset(val_files)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE_VAL, \n",
    "                                         shuffle=False, collate_fn=collate_val,\n",
    "                                         num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 19, 4])\n",
      "torch.Size([64, 30, 2])\n"
     ]
    }
   ],
   "source": [
    "# # Look at one data sample      \n",
    "for _, (data, target, agent_idxs, scene_idxs, vel) in enumerate(train_loader):\n",
    "    print(data.shape)\n",
    "    print(target.shape) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 19, 4])\n"
     ]
    }
   ],
   "source": [
    "# # Look at one data sample      \n",
    "for _, (data, agent_idxs, scene_idxs) in enumerate(val_loader):\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, velmodel, velopt):\n",
    "    # Set the model into training mode\n",
    "    model.train()    \n",
    "    velmodel.train()\n",
    "    \n",
    "    # Define the loss function.\n",
    "    criterion = torch.nn.MSELoss(reduction='mean')\n",
    "    velcrit = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "    total_loss = 0\n",
    "    vel_total_loss = 0\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        iterator = tqdm.notebook.tqdm(train_loader, total=int(len(train_loader)))\n",
    "        for _, batch in enumerate(iterator):\n",
    "            data, target, _, _, vel = batch\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            vel = vel.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "            velopt.zero_grad()\n",
    "            \n",
    "            outvel = velmodel(data)  \n",
    "            out = model(data, vel)\n",
    "            # Compute the loss       \n",
    "            velloss = torch.sqrt(velcrit(outvel, vel))\n",
    "            loss = torch.sqrt(criterion(out, target)) \n",
    "            vel_total_loss += velloss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform backpropagation\n",
    "            velloss.backward()\n",
    "            loss.backward()\n",
    "            # Update the weights\n",
    "            velopt.step()\n",
    "            optimizer.step()            \n",
    "\n",
    "            # Update the progress bar for tqdm\n",
    "            iterator.set_postfix(train_loss_vel=velloss.item(), train_loss=loss.item())\n",
    "            \n",
    "    return (total_loss * BATCH_SIZE_TRAIN) / len(train_files), (vel_total_loss * BATCH_SIZE_TRAIN) / len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, velmodel):\n",
    "    model.eval()    \n",
    "    velmodel.eval()\n",
    "    criterion = torch.nn.MSELoss(reduction='mean') \n",
    "    velcrit = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "    iterator = tqdm.notebook.tqdm(test_loader, total=int(len(test_loader)))\n",
    "    total_loss = 0\n",
    "    vel_total_loss = 0\n",
    "    \n",
    "    for _, batch in enumerate(iterator):\n",
    "        data, target, _, _, vel = batch\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        vel = vel.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outvel = velmodel(data)\n",
    "            out = model(data, outvel)            \n",
    "            velloss = torch.sqrt(criterion(outvel, vel))   \n",
    "            loss = torch.sqrt(criterion(out, target))        \n",
    "            total_loss += loss.item()\n",
    "            vel_total_loss += velloss.item()\n",
    "\n",
    "            iterator.set_postfix(test_loss_vel=velloss.item(), test_loss=loss.item())\n",
    "        \n",
    "    return (total_loss * BATCH_SIZE_TEST) / len(test_files), (vel_total_loss * BATCH_SIZE_TEST) / len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, DEVICE, train_loader, test_loader, optimizer, NUM_EPOCH, velmodel, velopt):\n",
    "    for t in range(1, NUM_EPOCH + 1):\n",
    "        train_loss = train(model, DEVICE, train_loader, optimizer, 1, velmodel, velopt)\n",
    "        test_loss = test(model, DEVICE, test_loader, velmodel)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        print(f'Epoch {t}: train_loss = {train_loss}, test_loss = {test_loss}')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, val_loader, path, velmodel):\n",
    "    \"\"\"\n",
    "    path: path to csv file to write predictions\n",
    "    \"\"\"\n",
    "    model.eval() \n",
    "    velmodel.eval()\n",
    "    \n",
    "    # Prep the output file\n",
    "    with open(PREDICTION_PATH, \"w\") as csv_file:\n",
    "        # Clear the csv file before appending data to it\n",
    "        csv_file.truncate()\n",
    "        # Write the header to the csv file\n",
    "        csv_file.writelines(CSV_HEADER)    \n",
    "    \n",
    "    # Make predictions\n",
    "    with open(path, \"a\") as pred_file:        \n",
    "        iterator = tqdm.notebook.tqdm(val_loader, total=int(len(val_loader)))\n",
    "        \n",
    "        for _, batch in enumerate(iterator):\n",
    "            data, scene_idxs, _ = batch\n",
    "            data = data.to(device) \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outvel = velmodel(data)\n",
    "                output = model(data, outvel)\n",
    "                # Convert the Tensor from GPU -> CPU -> NumPy array\n",
    "                np_out = output.cpu().detach().numpy()\n",
    "                \n",
    "                # Store only the predictions for the target agent and keep the positions, not the velocities\n",
    "                batch_size = np_out.shape[0]\n",
    "                \n",
    "                pred = np.zeros((batch_size, 60))\n",
    "                # The output should be a (batch size, time steps, num features out) tensor \n",
    "                # where the first two features are the out position x, y\n",
    "                for i in range(batch_size):\n",
    "                    pred[i] = np_out[i, :, :2].flatten()                          \n",
    "\n",
    "                # Form comma-separated string\n",
    "                s = []\n",
    "                for i in range(pred.shape[0]):\n",
    "                    s.append(','.join([str(scene_idxs[i])] + [str(v) for v in pred[i]]) + '\\n')\n",
    "\n",
    "                # Write data to file\n",
    "                pred_file.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ArgoNet(torch.nn.Module):\n",
    "#     \"\"\"\n",
    "#     Neural Network class - linear regression\n",
    "#     \"\"\"\n",
    "#     def __init__(self, device):\n",
    "#         super(ArgoNet, self).__init__() \n",
    "        \n",
    "#         self.device = device        \n",
    "#         # Linear regression for 1 agent     \n",
    "#         self.fc = nn.Linear((IN_LEN * N_FEAT_IN) + 60, OUT_LEN * N_FEAT_OUT)   \n",
    "    \n",
    "#     def forward(self, x, vel):\n",
    "#         x = x.reshape(x.shape[0], -1)\n",
    "#         vel = vel.reshape(vel.shape[0], -1)\n",
    "#         z = torch.cat((x, vel), dim=1)\n",
    "#         z = self.fc(z)            \n",
    "#         z = z.view(z.size(0), OUT_LEN, N_FEAT_OUT)  \n",
    "#         return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoNet(torch.nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(ArgoNet, self).__init__() \n",
    "        \n",
    "        self.device = device        \n",
    "        self.convA = nn.Sequential(\n",
    "            nn.Conv1d(19, 12, 3),\n",
    "            nn.SELU()\n",
    "        )\n",
    "        self.convB = nn.Sequential(\n",
    "            nn.Conv1d(30, 18, 1),\n",
    "            nn.SELU()\n",
    "        )   \n",
    "        self.fc = nn.Linear(60, 60)   \n",
    "    \n",
    "    def forward(self, x, vel):\n",
    "        x = self.convA(x)\n",
    "        vel = self.convB(vel)\n",
    "        z = torch.cat((x, vel), dim=1)\n",
    "        z = z.view(z.shape[0], -1)\n",
    "        z = self.fc(z)\n",
    "        z = z.view(z.shape[0], 30, 2)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VelNet(torch.nn.Module):\n",
    "#     \"\"\"\n",
    "#     Predicts output velocities given input positions and velocities\n",
    "#     \"\"\"\n",
    "#     def __init__(self, device):\n",
    "#         super(VelNet, self).__init__()         \n",
    "#         self.device = device        \n",
    "#         self.fc = nn.Linear(19 * 4, 30 * 2)\n",
    "   \n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = x.view(x.shape[0], -1)\n",
    "#         x = self.fc(x)\n",
    "#         x = x.view(x.shape[0], 30, 2)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VelNet(torch.nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(VelNet, self).__init__()         \n",
    "        self.device = device    \n",
    "        self.conv = nn.Conv1d(19, 12, 1)\n",
    "        self.act = nn.SELU()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(12 * 4, 120),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(120, 60)\n",
    "        )\n",
    "   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.act(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.shape[0], 30, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to save and reload a model\n",
    "MODEL_STATE = 'model_state_dict'\n",
    "OPTIMIZER_STATE = 'optimizer_state_dict'\n",
    "EPOCH_STATE = 'epoch'\n",
    "LOSS_STATE = 'loss'\n",
    "BATCH_STATE = 'batch'\n",
    "\n",
    "def save_model(path, model_state_dict, optimizer_state_dict, epoch, loss, batch):\n",
    "    to_save = {\n",
    "        MODEL_STATE: model_state_dict,\n",
    "        OPTIMIZER_STATE: optimizer_state_dict,\n",
    "        EPOCH_STATE: epoch,\n",
    "        LOSS_STATE: loss,\n",
    "        BATCH_STATE: batch\n",
    "    }\n",
    "    torch.save(to_save, path)\n",
    "    \n",
    "def load_model(path, model_to_load, optimizer_to_load):\n",
    "    checkpoint = torch.load(path)\n",
    "    model_to_load.load_state_dict(checkpoint[MODEL_STATE])\n",
    "    optimizer_to_load.load_state_dict(checkpoint[OPTIMIZER_STATE])\n",
    "    return checkpoint[EPOCH_STATE], checkpoint[LOSS_STATE], checkpoint[BATCH_STATE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Vel model parameters is 13380\n",
      "Number of Argo model parameters is 4914\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = ArgoNet(DEVICE).to(DEVICE)\n",
    "velmodel = VelNet(DEVICE).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "velopt = torch.optim.Adam(velmodel.parameters())\n",
    "\n",
    "\n",
    "print(f\"Number of Vel model parameters is {sum(p.numel() for p in velmodel.parameters())}\")\n",
    "print(f\"Number of Argo model parameters is {sum(p.numel() for p in model.parameters())}\")\n",
    "NUM_EPOCH = 1\n",
    "\n",
    "# used for visualizing the loss\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these two lines to save a model\n",
    "# save_model('sample.tar', model.state_dict(), optimizer.state_dict(), NUM_EPOCH, \n",
    "#            (train_losses[-1], test_losses[-1]), BATCH_SIZE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload a model\n",
    "# model = ArgoNet(DEVICE).to(DEVICE)\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "# load_model('one_hid_one_agent.tar', model, optimizer)\n",
    "# train_losses.clear()\n",
    "# test_losses.clear()\n",
    "# num_params = sum(p.numel() for p in model.parameters())   \n",
    "# print(f\"Number of model parameters is {num_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07875d6a11f84072a28c1437e2178d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2575.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-166-271859d7578b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_EPOCH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvelmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvelopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-42-b4a1ac812063>\u001b[0m in \u001b[0;36mtrain_test\u001b[1;34m(model, DEVICE, train_loader, test_loader, optimizer, NUM_EPOCH, velmodel, velopt)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_EPOCH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvelmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvelopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_EPOCH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvelmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvelopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvelmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-9ff2eee78a28>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, optimizer, epoch, velmodel, velopt)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0miterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1165\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1166\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-0eec3e4fb842>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mpkl_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkl_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_test(model, DEVICE, train_loader, test_loader, optimizer, NUM_EPOCH, velmodel, velopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9066c31ddb436f9bad25cfdba4fdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validate(model, DEVICE, val_loader, PREDICTION_PATH, velmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     # Initiliaze datasets and loaders\n",
    "#     train_dataset = ArgoverseDataset(train_files)\n",
    "#     train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, \n",
    "#                                                shuffle=True, collate_fn=collate_train_test, \n",
    "#                                                num_workers=N_WORKERS)\n",
    "#     test_dataset = ArgoverseDataset(test_files)\n",
    "#     test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, \n",
    "#                                               shuffle=False, collate_fn=collate_train_test, \n",
    "#                                               num_workers=N_WORKERS)\n",
    "#     for t in range(1, NUM_EPOCH + 1):\n",
    "#         # TRAIN\n",
    "#         model.train()    \n",
    "#         velmodel.train()\n",
    "#         criterion = torch.nn.MSELoss(reduction='mean')\n",
    "#         velcrit = torch.nn.MSELoss(reduction='mean')\n",
    "#         total_loss = 0\n",
    "#         vel_total_loss = 0\n",
    "\n",
    "#         iterator = tqdm.notebook.tqdm(train_loader, total=int(len(train_loader)))\n",
    "#         for _, batch in enumerate(iterator):\n",
    "#             data, target, _, _, vel = batch\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             vel = vel.to(device)\n",
    "\n",
    "#             optimizer.zero_grad()  \n",
    "#             velopt.zero_grad()\n",
    "\n",
    "#             outvel = velmodel(data)  \n",
    "#             out = model(data, outvel.data)\n",
    "#             # Compute the loss       \n",
    "#             velloss = torch.sqrt(velcrit(outvel, vel))\n",
    "#             loss = torch.sqrt(criterion(out, target)) \n",
    "#             vel_total_loss += velloss.item()\n",
    "#             total_loss += loss.item()\n",
    "\n",
    "#             # Perform backpropagation\n",
    "#             velloss.backward()\n",
    "#             loss.backward()\n",
    "#             # Update the weights\n",
    "#             velopt.step()\n",
    "#             optimizer.step()            \n",
    "\n",
    "#             # Update the progress bar for tqdm\n",
    "#             iterator.set_postfix(train_loss_vel=velloss.item(), train_loss=loss.item()) \n",
    "            \n",
    "#         total_loss = (total_loss * BATCH_SIZE_TRAIN) / len(train_files)\n",
    "#         vel_total_loss = (vel_total_loss * BATCH_SIZE_TRAIN) / len(train_files)\n",
    "#         train_losses.append((total_loss, vel_total_loss))\n",
    "   \n",
    "#         # TEST\n",
    "#         model.eval()    \n",
    "#         velmodel.eval()\n",
    "#         criterion = torch.nn.MSELoss(reduction='mean') \n",
    "#         velcrit = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "#         iterator = tqdm.notebook.tqdm(test_loader, total=int(len(test_loader)))\n",
    "#         total_loss = 0\n",
    "#         vel_total_loss = 0\n",
    "    \n",
    "#         for _, batch in enumerate(iterator):\n",
    "#             data, target, _, _, vel = batch\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             vel = vel.to(device)\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 outvel = velmodel(data)\n",
    "#                 out = model(data, outvel)            \n",
    "#                 velloss = torch.sqrt(criterion(outvel, vel))   \n",
    "#                 loss = torch.sqrt(criterion(out, target))        \n",
    "#                 total_loss += loss.item()\n",
    "#                 vel_total_loss += velloss.item()\n",
    "\n",
    "#                 iterator.set_postfix(test_loss_vel=velloss.item(), test_loss=loss.item())\n",
    "\n",
    "#         total_loss = (total_loss * BATCH_SIZE_TEST) / len(test_files)\n",
    "#         vel_total_loss = (vel_total_loss * BATCH_SIZE_TEST) / len(test_files)        \n",
    "#         test_losses.append((total_loss, vel_total_loss))\n",
    "\n",
    "#         print(f'Epoch {t}: train_loss = {train_losses[-1]}, test_loss = {test_losses[-1]}')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test(model, DEVICE, train_loader, test_loader, optimizer, NUM_EPOCH, velmodel, velopt)\n",
    "# validate(model, DEVICE, val_loader, PREDICTION_PATH, velmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(losses):\n",
    "    \"\"\"\n",
    "    Plots the losses over each training iteration. \n",
    "    Assumes that each element of the 'losses' list corresponds to the loss after each batch of train()\n",
    "    \"\"\"\n",
    "    t_iter = np.arange(1, len(losses) + 1, 1, dtype=int)\n",
    "    ax = sns.scatterplot(x=t_iter, y=losses, alpha=0.5)    \n",
    "    ax.set_xlabel('Batch iteration number')\n",
    "    ax.set_ylabel('Root-mean-square loss')\n",
    "    ax.set_title('Batch Iteration vs. Root-Mean-Square Loss')\n",
    "    plt.savefig('lossViter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_loss(train_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, device, loader):\n",
    "    \"\"\"\n",
    "    Compares some randomly selected data samples to the model's predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of data\n",
    "    _, (inp, out, scene_idxs, agent_idxs, masks) = next(enumerate(loader))\n",
    "    \n",
    "    # Move tensors to chosen device\n",
    "    inp, out = inp.to(device), out.to(device)\n",
    "    \n",
    "    # Sample number\n",
    "    i = 0\n",
    "    \n",
    "    # Scene idx\n",
    "    scene_idx = scene_idxs[i]\n",
    "        \n",
    "    # Get contiguous arrays of the ground truth output positions\n",
    "    truth = target[i].cpu().detach().numpy()\n",
    "    x = truth[:, 0]\n",
    "    y = truth[:, 1] \n",
    "        \n",
    "    # Get contiguous arrays of the prediction output positions\n",
    "    output = model(inp)    \n",
    "    pred = output[i].cpu().detach().numpy()\n",
    "    xh = pred[:, 0]\n",
    "    yh = pred[:, 0]    \n",
    "    \n",
    "    # Plot the ground truth and prediction positions\n",
    "    fig, (ax) = plt.subplots(nrows=1, ncols=1, figsize=(3, 3))\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_title('Scene ' + str(scene_idx))\n",
    "    ax.scatter(x, y, label='Ground Truth')\n",
    "    ax.scatter(xh, yh, label='Prediction')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(model, DEVICE, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
