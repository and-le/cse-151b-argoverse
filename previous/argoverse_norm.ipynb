{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0+cu92'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File system\n",
    "import os, os.path \n",
    "import pickle\n",
    "from glob import glob\n",
    "import sys\n",
    "\n",
    "# Workflow\n",
    "import random\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "\n",
    "# Computation\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Data visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(rc={\"figure.dpi\":100, 'savefig.dpi':100})\n",
    "sns.set_context('notebook')\n",
    "\n",
    "# Constants\n",
    "from argoverse_constants import *\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys to the pickle objects\n",
    "CITY = 'city'\n",
    "LANE = 'lane'\n",
    "LANE_NORM = 'lane_norm'\n",
    "SCENE_IDX = 'scene_idx'\n",
    "AGENT_ID = 'agent_id'\n",
    "P_IN = 'p_in'\n",
    "V_IN = 'v_in'\n",
    "P_OUT = 'p_out'\n",
    "V_OUT = 'v_out'\n",
    "CAR_MASK = 'car_mask'\n",
    "TRACK_ID = 'track_id'\n",
    "\n",
    "# Encode Miami as 0, Pittsburgh as 1\n",
    "MIA = 'MIA'\n",
    "PIT = 'PIT'  \n",
    "CITY_MAP = {MIA: 0, PIT: 1}\n",
    "\n",
    "# Transformed data keys\n",
    "LANE_IN = 'closest_lanes_in'\n",
    "NORM_IN = 'closest_lane_norms_in'\n",
    "LANE_OUT = 'closest_lanes_out'\n",
    "NORM_OUT = 'closest_lane_norms_out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset variables\n",
    "VALIDATION_PATH = './val_data/'\n",
    "ORIGINAL_PATH = './original_train_data/'\n",
    "TRANSFORMED_TRAIN_PATH = './transformed_train_data'\n",
    "TRANSFORMED_VAL_PATH = './transformed_val_data'\n",
    "STANDARDIZED_TRAIN_PATH = './standardized_train_data'\n",
    "STANDARDIZED_VAL_PATH = './standardized_val_data'\n",
    "\n",
    "# train_path = TRANSFORMED_TRAIN_PATH\n",
    "# val_path = TRANSFORMED_VAL_PATH\n",
    "\n",
    "train_path = STANDARDIZED_TRAIN_PATH\n",
    "val_path = STANDARDIZED_VAL_PATH\n",
    "\n",
    "# Path to model predictions on test set\n",
    "PREDICTION_PATH = './my_submission.csv'\n",
    "# Header of predictions CSV file\n",
    "CSV_HEADER = ['ID,'] + ['v' + str(i) + ',' for i in range(1, 60)] + ['v60', '\\n']\n",
    "\n",
    "# Get list of all training file names\n",
    "original_files = glob(os.path.join(train_path, '*'))\n",
    "\n",
    "# 80-20 train-test split\n",
    "train_files = random.sample(original_files, int(len(original_files) * 0.8))\n",
    "test_files = list(set(original_files) - set(train_files))\n",
    "\n",
    "# Validation\n",
    "val_files = glob(os.path.join(val_path, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Control variables\n",
    "USE_ONE_AGENT = True\n",
    "PREDICT_ONE_AGENT = True  # controls whether 60-agent inputs are mapped to just the target agent's outputs\n",
    "\n",
    "NUM_AGENTS = 1 if USE_ONE_AGENT else 60\n",
    "IN_LEN = 19\n",
    "OUT_LEN = 30\n",
    "\n",
    "# Controls how many features to use\n",
    "N_FEAT_IN = 4\n",
    "N_FEAT_OUT = 2\n",
    "\n",
    "APPLY_NORM = True\n",
    "APPLY_ST = False  # standardization\n",
    "APPLY_MM = True  # min-max\n",
    "\n",
    "# Batch variables\n",
    "BATCH_SIZE_TRAIN = 64\n",
    "BATCH_SIZE_TEST = BATCH_SIZE_TRAIN\n",
    "BATCH_SIZE_VAL = 32\n",
    "N_WORKERS = 4\n",
    "# Windows doesn't support anything but N_WORKERS = 0 for the DataLoader\n",
    "if 'win' in sys.platform:\n",
    "    N_WORKERS = 0\n",
    "N_WORKERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x, mean, std):\n",
    "    return (x - mean) / std\n",
    "def inv_standardize(x, mean, std):\n",
    "    return (x * std) + mean\n",
    "\n",
    "def min_max_scale(x, minval, maxval):\n",
    "    return (x - minval) / (maxval - minval)\n",
    "def inv_min_max_scale(x, minval, maxval):\n",
    "    return (x * (maxval - minval)) + minval\n",
    "\n",
    "def scale(x, minval, maxval, mean, std):\n",
    "    if APPLY_MM:\n",
    "        return min_max_scale(x, minval, maxval)\n",
    "    else:\n",
    "        return standardize(x, mean, std)\n",
    "\n",
    "def descale(x, minval, maxval, mean, std):\n",
    "    if APPLY_MM:\n",
    "        return inv_min_max_scale(x, minval, maxval)\n",
    "    else:\n",
    "        return inv_standardize(x, mean, std)\n",
    "\n",
    "def normalize_inpos(inp, city):\n",
    "    if city == 0:\n",
    "        inp[:, 0] = scale(inp[:, 0], MIA_PX_IN_MIN, MIA_PX_IN_MAX, MIA_PX_IN_MEAN, MIA_PX_IN_STD)\n",
    "        inp[:, 1] = scale(inp[:, 0], MIA_PY_IN_MIN, MIA_PY_IN_MAX, MIA_PY_IN_MEAN, MIA_PY_IN_STD)\n",
    "    else:\n",
    "        inp[:, 0] = scale(inp[:, 0], PIT_PX_IN_MIN, PIT_PX_IN_MAX, PIT_PX_IN_MEAN, PIT_PX_IN_STD)\n",
    "        inp[:, 1] = scale(inp[:, 0], PIT_PY_IN_MIN, PIT_PY_IN_MAX, PIT_PY_IN_MEAN, PIT_PY_IN_STD)        \n",
    "    return inp\n",
    "\n",
    "def normalize_invel(inp, city):\n",
    "    if city == 0:\n",
    "        inp[:, 0] = scale(inp[:, 0], MIA_VX_IN_MIN, MIA_VX_IN_MAX, MIA_VX_IN_MEAN, MIA_VX_IN_STD)\n",
    "        inp[:, 1] = scale(inp[:, 0], MIA_VY_IN_MIN, MIA_VY_IN_MAX, MIA_VY_IN_MEAN, MIA_VY_IN_STD)\n",
    "    else:\n",
    "        inp[:, 0] = scale(inp[:, 0], PIT_VX_IN_MIN, PIT_VX_IN_MAX, PIT_VX_IN_MEAN, PIT_VX_IN_STD)\n",
    "        inp[:, 1] = scale(inp[:, 0], PIT_VY_IN_MIN, PIT_VY_IN_MAX, PIT_VY_IN_MEAN, PIT_VY_IN_STD)        \n",
    "    return inp \n",
    "\n",
    "\n",
    "def normalize_outpos(inp, city):\n",
    "    if city == 0:\n",
    "        inp[:, 0] = scale(inp[:, 0], MIA_PX_OUT_MIN, MIA_PX_OUT_MAX, MIA_PX_OUT_MEAN, MIA_PX_OUT_STD)\n",
    "        inp[:, 1] = scale(inp[:, 0], MIA_PY_OUT_MIN, MIA_PY_OUT_MAX, MIA_PY_OUT_MEAN, MIA_PX_OUT_STD)\n",
    "    else:\n",
    "        inp[:, 0] = scale(inp[:, 0], PIT_PX_OUT_MIN, PIT_PX_OUT_MAX, PIT_PX_OUT_MEAN, PIT_PX_OUT_STD)\n",
    "        inp[:, 1] = scale(inp[:, 0], PIT_PY_OUT_MIN, PIT_PY_OUT_MAX, PIT_PY_OUT_MEAN, PIT_PY_OUT_STD)        \n",
    "    return inp \n",
    "\n",
    "\n",
    "def normalize_outvel(inp, city):\n",
    "    if city == 0:\n",
    "        inp[:, 0] = scale(inp[:, 0], MIA_VX_OUT_MIN, MIA_VX_OUT_MAX, MIA_VX_OUT_MEAN, MIA_VX_OUT_STD)\n",
    "        inp[:, 1] = scale(inp[:, 0], MIA_VY_OUT_MIN, MIA_VY_OUT_MAX, MIA_VY_OUT_MEAN, MIA_VX_OUT_STD)\n",
    "    else:\n",
    "        inp[:, 0] = scale(inp[:, 0], PIT_VX_OUT_MIN, PIT_VX_OUT_MAX, PIT_VX_OUT_MEAN, PIT_VX_OUT_STD)\n",
    "        inp[:, 1] = scale(inp[:, 0], PIT_VY_OUT_MIN, PIT_VY_OUT_MAX, PIT_VY_OUT_MEAN, PIT_VY_OUT_STD)        \n",
    "    return inp  \n",
    "\n",
    "\n",
    "def inv_norm_outpos(out, cities):\n",
    "    batch_size = out.shape[0]\n",
    "    for b in range(batch_size):\n",
    "        if cities[b] == 0:  # Miami\n",
    "            out[b, :, 0] = descale(out[b, :, 0], MIA_PX_OUT_MIN, MIA_PX_OUT_MAX, MIA_PX_OUT_MEAN, MIA_PX_OUT_STD)\n",
    "            out[b, :, 1] = descale(out[b, :, 1], MIA_PY_OUT_MIN, MIA_PY_OUT_MAX, MIA_PY_OUT_MEAN, MIA_PX_OUT_STD)\n",
    "        else:  # Pittsburgh\n",
    "            out[b, :, 0] = descale(out[b, :, 0], PIT_PX_OUT_MIN, PIT_PX_OUT_MAX, PIT_PX_OUT_MEAN, PIT_PX_OUT_STD)\n",
    "            out[b, :, 1] = descale(out[b, :, 1], PIT_PY_OUT_MIN, PIT_PY_OUT_MAX, PIT_PY_OUT_MEAN, PIT_PX_OUT_STD) \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.files = files\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.files[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_train_test(batch):\n",
    "    \"\"\" \n",
    "    Custom collate_fn function to be used for DataLoader.    \n",
    "    The input tensor is organized as 19 rows, where each row has 4 columns: px, py, vx, vy\n",
    "    \n",
    "    The output tensor can be organized in 2 ways:\n",
    "    A) The output tensor is organized as 120 rows, where each row has 1 column. \n",
    "    Each contiguous sequence of 4 elements is px, py, vx, vy\n",
    "    \n",
    "    B) The input tensor is organized as 30 rows, where each row has 4 columns: px, py, vx, vy\n",
    "    \"\"\"    \n",
    "    inp = []        \n",
    "    out = []\n",
    "    agent_idxs = []\n",
    "    scene_idxs = []\n",
    "    city_ids = []\n",
    "    for scene in batch:\n",
    "        # Get the target agent id\n",
    "        agent_id = scene[AGENT_ID]        \n",
    "        # Get the matrix of all agents\n",
    "        track_id = scene[TRACK_ID]        \n",
    "        # Get the location of the target agent in the matrix\n",
    "        idx = np.nonzero(track_id[:, 0] == agent_id)[0][0]\n",
    "        \n",
    "        # Number of time steps in the input and output sequences\n",
    "        inlen = scene[P_IN].shape[1]\n",
    "        outlen = scene[P_OUT].shape[1]\n",
    "        \n",
    "        # Aliases of scene variables for convenience\n",
    "        pin, pout, vin, vout = scene[P_IN], scene[P_OUT], scene[V_IN], scene[V_OUT]\n",
    "        lanein, laneout, normin, normout = scene[LANE_IN], scene[LANE_OUT], scene[NORM_IN], scene[NORM_OUT]\n",
    "        \n",
    "        # Use these lines to include only the target agent.\n",
    "        # Training with just one agent is faster and preferred for experimentation\n",
    "        if USE_ONE_AGENT:  \n",
    "            if scene[CITY] == MIA:\n",
    "                cities = np.zeros((inlen, 1)) \n",
    "            else:\n",
    "                cities = np.ones((inlen, 1)) \n",
    "\n",
    "            # Use this line to include all input features\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], lanein[idx], normin[idx], cities), axis=1)    \n",
    "\n",
    "            # Lane only\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], lanein[idx], normin[idx]), axis=1) \n",
    "\n",
    "            # Only include cities\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], cities), axis=1)     \n",
    "\n",
    "            # Only include pos/vel\n",
    "#             if APPLY_NORM:\n",
    "#                 pin[idx] = normalize_inpos(pin[idx], CITY_MAP[scene[CITY]])\n",
    "#                 vin[idx] = normalize_invel(vin[idx], CITY_MAP[scene[CITY]])\n",
    "#                 pout[idx] = normalize_outpos(pout[idx], CITY_MAP[scene[CITY]])\n",
    "\n",
    "            inp_tens = np.concatenate((pin[idx], vin[idx]), axis=1)\n",
    "\n",
    "            # All output features\n",
    "#             out_tens = np.concatenate((pout[idx], vout[idx], laneout[idx], normout[idx]), axis=1)\n",
    "            # Only include output position and velocity\n",
    "#             out_tens = np.concatenate((pout[idx], vout[idx]), axis=1)   \n",
    "        \n",
    "            out_tens = pout[idx]\n",
    "            \n",
    "        # Use these lines to include all 60 agents, even the dummy agents.\n",
    "        # Training with all 60 agents is much slower than with just one agent.\n",
    "        else:\n",
    "            num_agents = pin.shape[0]\n",
    "            if scene[CITY] == MIA:\n",
    "                cities = np.zeros((num_agents, inlen, 1)) \n",
    "            else:\n",
    "                cities = np.ones((num_agents, inlen, 1))  \n",
    "                \n",
    "            # Include all features\n",
    "#             inp_tens = np.concatenate((pin, vin, lanein, normin, cities), axis=2)  \n",
    "            # Lane only\n",
    "#             inp_tens = np.concatenate((pin, vin, lanein, normin), axis=2)   \n",
    "            # Include only cities\n",
    "            inp_tens = np.concatenate((pin, vin, cities), axis=2) \n",
    "            # Include only pos/vel\n",
    "#             inp_tens = np.concatenate((pin, vin), axis=2)\n",
    "            \n",
    "            # Makes predictions for only the target agent\n",
    "            if PREDICT_ONE_AGENT:\n",
    "                # All features\n",
    "#                 out_tens = np.concatenate((pout[idx], vout[idx], laneout[idx], normout[idx]), axis=1)                \n",
    "                # Pos/vel\n",
    "                out_tens = np.concatenate((pout[idx], vout[idx]), axis=1)\n",
    "\n",
    "            # Makes predictions for all 60 agents\n",
    "            else:\n",
    "                # All features\n",
    "#                 out_tens = np.concatenate((pout, vout, laneout, normout), axis=2)                \n",
    "                # pv\n",
    "                out_tens = np.concatenate((pout, vout), axis=2) \n",
    "        \n",
    "        inp.append(inp_tens)\n",
    "        out.append(out_tens)        \n",
    "        scene_idxs.append(scene[SCENE_IDX]) \n",
    "        agent_idxs.append(idx)\n",
    "        city_ids.append(CITY_MAP[scene[CITY]])\n",
    "\n",
    "    inp = torch.FloatTensor(inp)\n",
    "    out = torch.FloatTensor(out)\n",
    "    return [inp, out, scene_idxs, agent_idxs, city_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_val(batch):\n",
    "    \"\"\" \n",
    "    Custom collate_fn for validation dataset. The validation data do not contain output values.   \n",
    "    The input tensor is organized as 19 rows, where each row has 4 columns: px, py, vx, vy\n",
    "    \"\"\"   \n",
    "    inp = []\n",
    "    scene_idxs = []\n",
    "    agent_idxs = []\n",
    "    city_ids = []\n",
    "    \n",
    "    for scene in batch:\n",
    "        # Get the target agent id\n",
    "        agent_id = scene[AGENT_ID]        \n",
    "        # Get the matrix of all agents\n",
    "        track_id = scene[TRACK_ID]        \n",
    "        # Get the location of the target agent in the matrix\n",
    "        idx = np.nonzero(track_id[:, 0] == agent_id)[0][0]\n",
    "        \n",
    "        inlen = scene[P_IN].shape[1]\n",
    "        \n",
    "        # Aliases of scene variables for convenience\n",
    "        pin, vin = scene[P_IN], scene[V_IN]\n",
    "        lanein, normin = scene[LANE_IN], scene[NORM_IN]\n",
    "        num_agents = scene[P_IN].shape[0]\n",
    "        \n",
    "        # Use these lines to include only the target agent.\n",
    "        if USE_ONE_AGENT:\n",
    "            if scene[CITY] == MIA:\n",
    "                cities = np.zeros((inlen, 1)) \n",
    "            else:\n",
    "                cities = np.ones((inlen, 1)) \n",
    "            # All\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], lanein[idx], normin[idx], cities), axis=1)\n",
    "            # Lane only\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], lanein[idx], normin[idx]), axis=1)\n",
    "            # Cities\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], cities), axis=1)  \n",
    "            # Pos/vel\n",
    "#             if APPLY_NORM:\n",
    "#                 pin[idx] = normalize_inpos(pin[idx], CITY_MAP[scene[CITY]])\n",
    "#                 vin[idx] = normalize_invel(vin[idx], CITY_MAP[scene[CITY]])\n",
    "            inp_tens = np.concatenate((pin[idx], vin[idx]), axis=1)  \n",
    "\n",
    "        # Use these lines to include all 60 agents\n",
    "        else:\n",
    "            if scene[CITY] == MIA:\n",
    "                cities = np.zeros((num_agents, inlen, 1)) \n",
    "            else:\n",
    "                cities = np.ones((num_agents, inlen, 1))\n",
    "            # All features\n",
    "#             inp_tens = np.concatenate( (pin, vin, lanein, normin, cities), axis=2)       \n",
    "            # Lane only\n",
    "#             inp_tens = np.concatenate( (pin, vin, lanein, normin), axis=2)\n",
    "            # Cities\n",
    "            inp_tens = np.concatenate( (pin, vin, cities), axis=2)             \n",
    "            # pv\n",
    "#             inp_tens = np.concatenate( (pin, vin), axis=2)  \n",
    "        \n",
    "        inp.append(inp_tens)        \n",
    "        scene_idxs.append(scene[SCENE_IDX])\n",
    "        agent_idxs.append(idx)\n",
    "        city_ids.append(CITY_MAP[scene[CITY]])        \n",
    "        \n",
    "    inp = torch.FloatTensor(inp)    \n",
    "    return [inp, scene_idxs, agent_idxs, city_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliaze datasets and loaders\n",
    "\n",
    "train_dataset = ArgoverseDataset(train_files)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, \n",
    "                                           shuffle=True, collate_fn=collate_train_test, \n",
    "                                           num_workers=N_WORKERS)\n",
    "test_dataset = ArgoverseDataset(test_files)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, \n",
    "                                          shuffle=False, collate_fn=collate_train_test, \n",
    "                                          num_workers=N_WORKERS)\n",
    "val_dataset = ArgoverseDataset(val_files)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE_VAL, \n",
    "                                         shuffle=False, collate_fn=collate_val,\n",
    "                                         num_workers=N_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 19, 4])\n",
      "torch.Size([64, 30, 2])\n"
     ]
    }
   ],
   "source": [
    "# Look at one data sample      \n",
    "for _, (data, target, agent_idxs, scene_idxs, cities) in enumerate(train_loader):\n",
    "    print(data.shape)\n",
    "    print(target.shape) \n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 19, 4])\n"
     ]
    }
   ],
   "source": [
    "# Look at one data sample      \n",
    "for _, (data, agent_idxs, scene_idxs, masks) in enumerate(val_loader):\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # Set the model into training mode\n",
    "    model.train()    \n",
    "    \n",
    "    # Define the loss function.\n",
    "    criterion = torch.nn.MSELoss(reduction='mean')\n",
    "    total_loss = 0    \n",
    "    for i in range(epoch):\n",
    "        h = c = None # Hidden states      \n",
    "\n",
    "        iterator = tqdm.notebook.tqdm(train_loader, total=int(len(train_loader)))\n",
    "        for _, batch in enumerate(iterator):\n",
    "            data, target, scene_idxs, agent_idxs, cities = batch\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()            \n",
    "    \n",
    "            out = model(data)\n",
    "            # Compute the loss\n",
    "            # Rescale values\n",
    "            out = inv_norm_outpos(out, cities)\n",
    "            target = inv_norm_outpos(target, cities)\n",
    "            \n",
    "            loss = torch.sqrt(criterion(out, target))            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform backpropagation\n",
    "            loss.backward()\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the progress bar for tqdm\n",
    "            iterator.set_postfix(train_loss=loss.item())\n",
    "            \n",
    "    return (total_loss * BATCH_SIZE_TRAIN) / len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()    \n",
    "    criterion = torch.nn.MSELoss(reduction='mean')    \n",
    "    iterator = tqdm.notebook.tqdm(test_loader, total=int(len(test_loader)))\n",
    "    total_loss = 0\n",
    "    \n",
    "    for _, batch in enumerate(iterator):\n",
    "        data, target, scene_idxs, agent_idxs, masks = batch\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            out = model(data)\n",
    "            # Rescale values\n",
    "            out = inv_norm_outpos(out, cities)\n",
    "            target = inv_norm_outpos(target, cities)\n",
    "            \n",
    "            loss = torch.sqrt(criterion(out, target))        \n",
    "            total_loss += loss.item()\n",
    "                \n",
    "            iterator.set_postfix(test_loss=loss.item())\n",
    "        \n",
    "    return (total_loss * BATCH_SIZE_TEST) / len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, DEVICE, train_loader, optimizer, NUM_EPOCH):\n",
    "    for t in range(1, NUM_EPOCH + 1):\n",
    "        train_loss = train(model, DEVICE, train_loader, optimizer, 1)\n",
    "        test_loss = test(model, DEVICE, test_loader)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        print(f'Epoch {t}: train_loss = {train_loss}, test_loss = {test_loss}')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, val_loader, path):\n",
    "    \"\"\"\n",
    "    path: path to csv file to write predictions\n",
    "    \"\"\"\n",
    "    model.eval()   \n",
    "    \n",
    "    # Prep the output file\n",
    "    with open(PREDICTION_PATH, \"w\") as csv_file:\n",
    "        # Clear the csv file before appending data to it\n",
    "        csv_file.truncate()\n",
    "        # Write the header to the csv file\n",
    "        csv_file.writelines(CSV_HEADER)    \n",
    "    \n",
    "    # Make predictions\n",
    "    with open(path, \"a\") as pred_file:        \n",
    "        iterator = tqdm.notebook.tqdm(val_loader, total=int(len(val_loader)))\n",
    "        \n",
    "        for _, batch in enumerate(iterator):\n",
    "            data, scene_idxs, agent_idxs, cities = batch\n",
    "            data = data.to(device) \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "                output = inv_norm_outpos(data, cities)\n",
    "                # Convert the Tensor from GPU -> CPU -> NumPy array\n",
    "                np_out = output.cpu().detach().numpy()\n",
    "                \n",
    "                # Store only the predictions for the target agent and keep the positions, not the velocities\n",
    "                batch_size = np_out.shape[0]\n",
    "                \n",
    "                pred = np.zeros((batch_size, 60))\n",
    "                if PREDICT_ONE_AGENT:\n",
    "                    # The output should be a (batch size, time steps, num features out) tensor \n",
    "                    # where the first two features are the out position x, y\n",
    "                    for i in range(batch_size):\n",
    "                        pred[i] = np_out[i, :, :2].flatten()\n",
    "                else:\n",
    "                    # The output should be a (batch size, num agents, time steps, num features out) tensor \n",
    "                    # where the first two features are the input position and the output position\n",
    "                    for i in range(batch_size):\n",
    "                        idx = agent_idxs[i]\n",
    "                        pred[i] = np_out[i, idx, :, :2].flatten()                    \n",
    "\n",
    "                # Form comma-separated string\n",
    "                s = []\n",
    "                for i in range(pred.shape[0]):\n",
    "                    s.append(','.join([str(scene_idxs[i])] + [str(v) for v in pred[i]]) + '\\n')\n",
    "\n",
    "                # Write data to file\n",
    "                pred_file.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Network class - linear regression\n",
    "    \"\"\"\n",
    "    def __init__(self, device):\n",
    "        super(ArgoNet, self).__init__() \n",
    "        \n",
    "        self.device = device        \n",
    "        # Linear regression for 1 agent     \n",
    "        if PREDICT_ONE_AGENT:\n",
    "            self.fc = nn.Linear(NUM_AGENTS * IN_LEN * N_FEAT_IN, 1 * OUT_LEN * N_FEAT_OUT)\n",
    "        else:\n",
    "            self.fc = nn.Linear(NUM_AGENTS * IN_LEN * N_FEAT_IN, NUM_AGENTS * OUT_LEN * N_FEAT_OUT)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # flatten result\n",
    "        x = self.fc(x)            \n",
    "        if PREDICT_ONE_AGENT:\n",
    "            x = x.view(x.size(0), OUT_LEN, N_FEAT_OUT)\n",
    "        else:\n",
    "            x = x.view(x.size(0), NUM_AGENTS, OUT_LEN, N_FEAT_OUT)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ArgoNet(torch.nn.Module):\n",
    "#     \"\"\"\n",
    "#     Neural Network class - 1 hidden layer\n",
    "#     \"\"\"\n",
    "#     def __init__(self, device):\n",
    "#         super(ArgoNet, self).__init__() \n",
    "        \n",
    "#         self.device = device \n",
    "#         self.hidden_size = IN_LEN * N_FEAT_IN * 30\n",
    "#         if PREDICT_ONE_AGENT:\n",
    "#             self.fc = nn.Sequential(\n",
    "#                 nn.Linear(NUM_AGENTS * IN_LEN * N_FEAT_IN, 1 * self.hidden_size),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(self.hidden_size, 1 * OUT_LEN * N_FEAT_OUT)\n",
    "#             )\n",
    "#         else:\n",
    "#             self.fc = nn.Linear(NUM_AGENTS * IN_LEN * N_FEAT_IN, NUM_AGENTS * OUT_LEN * N_FEAT_OUT)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = x.view(x.size(0), -1)  # flatten result\n",
    "#         x = self.fc(x)            \n",
    "#         if PREDICT_ONE_AGENT:\n",
    "#             x = x.view(x.size(0), OUT_LEN, N_FEAT_OUT)\n",
    "#         else:\n",
    "#             x = x.view(x.size(0), NUM_AGENTS, OUT_LEN, N_FEAT_OUT)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ArgoNet(torch.nn.Module):\n",
    "#     \"\"\"\n",
    "#     Neural Network class - 2 hidden layers\n",
    "#     \"\"\"\n",
    "#     def __init__(self, device):\n",
    "#         super(ArgoNet, self).__init__() \n",
    "        \n",
    "#         self.device = device \n",
    "#         # Linear regression for 1 agent     \n",
    "#         if PREDICT_ONE_AGENT:\n",
    "#             self.fc = nn.Sequential(\n",
    "#                 nn.Linear(NUM_AGENTS * IN_LEN * N_FEAT_IN, 1 * 512),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(512, 1024),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(1024, 1 * OUT_LEN * N_FEAT_OUT)\n",
    "#             )\n",
    "#         else:\n",
    "#             self.fc = nn.Linear(NUM_AGENTS * IN_LEN * N_FEAT_IN, NUM_AGENTS * OUT_LEN * N_FEAT_OUT)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = x.view(x.size(0), -1)  # flatten result\n",
    "#         x = self.fc(x)            \n",
    "#         if PREDICT_ONE_AGENT:\n",
    "#             x = x.view(x.size(0), OUT_LEN, N_FEAT_OUT)\n",
    "#         else:\n",
    "#             x = x.view(x.size(0), NUM_AGENTS, OUT_LEN, N_FEAT_OUT)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to save and reload a model\n",
    "MODEL_STATE = 'model_state_dict'\n",
    "OPTIMIZER_STATE = 'optimizer_state_dict'\n",
    "EPOCH_STATE = 'epoch'\n",
    "LOSS_STATE = 'loss'\n",
    "BATCH_STATE = 'batch'\n",
    "\n",
    "def save_model(path, model_state_dict, optimizer_state_dict, epoch, loss, batch):\n",
    "    to_save = {\n",
    "        MODEL_STATE: model_state_dict,\n",
    "        OPTIMIZER_STATE: optimizer_state_dict,\n",
    "        EPOCH_STATE: epoch,\n",
    "        LOSS_STATE: loss,\n",
    "        BATCH_STATE: batch\n",
    "    }\n",
    "    torch.save(to_save, path)\n",
    "    \n",
    "def load_model(path, model_to_load, optimizer_to_load):\n",
    "    checkpoint = torch.load(path)\n",
    "    model_to_load.load_state_dict(checkpoint[MODEL_STATE])\n",
    "    optimizer_to_load.load_state_dict(checkpoint[OPTIMIZER_STATE])\n",
    "    return checkpoint[EPOCH_STATE], checkpoint[LOSS_STATE], checkpoint[BATCH_STATE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters is 4620\n"
     ]
    }
   ],
   "source": [
    "model = ArgoNet(DEVICE).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# learning_rate = 1e-1\n",
    "# momentum = 0.9\n",
    "# weight_decay = 1\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "# optimizer = torch.optim.Adadelta(model.parameters())  # Used to generate visualizations in report\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), betas=(0.5, 0.9))\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())   \n",
    "print(f\"Number of model parameters is {num_params}\")\n",
    "NUM_EPOCH = 3\n",
    "\n",
    "# used for visualizing the loss\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these two lines to save a model\n",
    "# save_model('two_hid_one_agent_ep6.tar', model.state_dict(), optimizer.state_dict(), NUM_EPOCH, \n",
    "#            (train_losses[-1], test_losses[-1]), BATCH_SIZE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload a model\n",
    "# model = ArgoNet(DEVICE).to(DEVICE)\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "# load_model('one_hid_one_agent.tar', model, optimizer)\n",
    "# train_losses.clear()\n",
    "# test_losses.clear()\n",
    "# num_params = sum(p.numel() for p in model.parameters())   \n",
    "# print(f\"Number of model parameters is {num_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da446c1c33bb47c3af9d96aac263a7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2575.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_test(model, DEVICE, train_loader, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "validate(model, DEVICE, val_loader, PREDICTION_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(losses):\n",
    "    \"\"\"\n",
    "    Plots the losses over each training iteration. \n",
    "    Assumes that each element of the 'losses' list corresponds to the loss after each batch of train()\n",
    "    \"\"\"\n",
    "    t_iter = np.arange(1, len(losses) + 1, 1, dtype=int)\n",
    "    ax = sns.scatterplot(x=t_iter, y=losses, alpha=0.5)    \n",
    "    ax.set_xlabel('Batch iteration number')\n",
    "    ax.set_ylabel('Root-mean-square loss')\n",
    "    ax.set_title('Batch Iteration vs. Root-Mean-Square Loss')\n",
    "    plt.savefig('lossViter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_loss(train_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, device, loader):\n",
    "    \"\"\"\n",
    "    Compares some randomly selected data samples to the model's predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of data\n",
    "    _, (inp, out, scene_idxs, agent_idxs, masks) = next(enumerate(loader))\n",
    "    \n",
    "    # Move tensors to chosen device\n",
    "    inp, out = inp.to(device), out.to(device)\n",
    "    \n",
    "    # Sample number\n",
    "    i = 0\n",
    "    \n",
    "    # Scene idx\n",
    "    scene_idx = scene_idxs[i]\n",
    "        \n",
    "    # Get contiguous arrays of the ground truth output positions\n",
    "    truth = target[i].cpu().detach().numpy()\n",
    "    x = truth[:, 0]\n",
    "    y = truth[:, 1] \n",
    "        \n",
    "    # Get contiguous arrays of the prediction output positions\n",
    "    output = model(inp)    \n",
    "    pred = output[i].cpu().detach().numpy()\n",
    "    xh = pred[:, 0]\n",
    "    yh = pred[:, 0]    \n",
    "    \n",
    "    # Plot the ground truth and prediction positions\n",
    "    fig, (ax) = plt.subplots(nrows=1, ncols=1, figsize=(3, 3))\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_title('Scene ' + str(scene_idx))\n",
    "    ax.scatter(x, y, label='Ground Truth')\n",
    "    ax.scatter(xh, yh, label='Prediction')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(model, DEVICE, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
