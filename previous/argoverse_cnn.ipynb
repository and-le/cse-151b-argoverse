{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0+cu111'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File system\n",
    "import os, os.path \n",
    "import pickle\n",
    "from glob import glob\n",
    "import sys\n",
    "\n",
    "# Workflow\n",
    "import random\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "\n",
    "# Computation\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Data visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(rc={\"figure.dpi\":100, 'savefig.dpi':100})\n",
    "sns.set_context('notebook')\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys to the pickle objects\n",
    "CITY = 'city'\n",
    "LANE = 'lane'\n",
    "LANE_NORM = 'lane_norm'\n",
    "SCENE_IDX = 'scene_idx'\n",
    "AGENT_ID = 'agent_id'\n",
    "P_IN = 'p_in'\n",
    "V_IN = 'v_in'\n",
    "P_OUT = 'p_out'\n",
    "V_OUT = 'v_out'\n",
    "CAR_MASK = 'car_mask'\n",
    "TRACK_ID = 'track_id'\n",
    "\n",
    "# Encode Miami as 0, Pittsburgh as 1\n",
    "MIA = 'MIA'\n",
    "PIT = 'PIT'  \n",
    "CITY_MAP = {MIA: 0, PIT: 1}\n",
    "\n",
    "# Transformed data keys\n",
    "LANE_IN = 'closest_lanes_in'\n",
    "NORM_IN = 'closest_lane_norms_in'\n",
    "LANE_OUT = 'closest_lanes_out'\n",
    "NORM_OUT = 'closest_lane_norms_out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset variables\n",
    "VALIDATION_PATH = './val_data/'\n",
    "ORIGINAL_PATH = './original_train_data/'\n",
    "TRANSFORMED_TRAIN_PATH = './transformed_train_data'\n",
    "TRANSFORMED_VAL_PATH = './transformed_val_data'\n",
    "\n",
    "train_path = TRANSFORMED_TRAIN_PATH\n",
    "val_path = TRANSFORMED_VAL_PATH\n",
    "\n",
    "# Path to model predictions on test set\n",
    "PREDICTION_PATH = './my_submission.csv'\n",
    "# Header of predictions CSV file\n",
    "CSV_HEADER = ['ID,'] + ['v' + str(i) + ',' for i in range(1, 60)] + ['v60', '\\n']\n",
    "\n",
    "# Get list of all training file names\n",
    "original_files = glob(os.path.join(train_path, '*'))\n",
    "\n",
    "# train-test split\n",
    "TRAIN_TEST_RATIO = 0.8  # Percent that are train files\n",
    "train_files = random.sample(original_files, int(len(original_files) * TRAIN_TEST_RATIO))\n",
    "test_files = list(set(original_files) - set(train_files))\n",
    "\n",
    "# Validation\n",
    "val_files = glob(os.path.join(val_path, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Control variables\n",
    "NUM_AGENTS = 1\n",
    "IN_LEN = 19\n",
    "OUT_LEN = 30\n",
    "\n",
    "# Controls how many features to use\n",
    "N_FEAT_IN = 4\n",
    "N_FEAT_OUT = 2\n",
    "\n",
    "# Batch variables\n",
    "BATCH_SIZE_TRAIN = 64\n",
    "BATCH_SIZE_TEST = BATCH_SIZE_TRAIN\n",
    "BATCH_SIZE_VAL = 32\n",
    "N_WORKERS = 4\n",
    "# Windows doesn't support anything but N_WORKERS = 0 for the DataLoader\n",
    "if 'win' in sys.platform:\n",
    "    N_WORKERS = 0\n",
    "N_WORKERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.files = files\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.files[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_train_test(batch):\n",
    "    \"\"\" \n",
    "    Custom collate_fn function to be used for DataLoader.    \n",
    "    \"\"\"    \n",
    "    inp = []        \n",
    "    out = []\n",
    "    agent_idxs = []\n",
    "    scene_idxs = []\n",
    "    city_ids = []\n",
    "    for scene in batch:\n",
    "        # Get the target agent id\n",
    "        agent_id = scene[AGENT_ID]        \n",
    "        # Get the matrix of all agents\n",
    "        track_id = scene[TRACK_ID]        \n",
    "        # Get the location of the target agent in the matrix\n",
    "        idx = np.nonzero(track_id[:, 0] == agent_id)[0][0]\n",
    "        \n",
    "        # Number of time steps in the input and output sequences\n",
    "        inlen = scene[P_IN].shape[1]\n",
    "        outlen = scene[P_OUT].shape[1]\n",
    "        \n",
    "        # Aliases of scene variables for convenience\n",
    "        pin, pout, vin, vout = scene[P_IN], scene[P_OUT], scene[V_IN], scene[V_OUT]\n",
    "        lanein, laneout, normin, normout = scene[LANE_IN], scene[LANE_OUT], scene[NORM_IN], scene[NORM_OUT]\n",
    "        \n",
    "        if scene[CITY] == MIA:\n",
    "            cities = np.zeros((inlen, 1)) \n",
    "        else:\n",
    "            cities = np.ones((inlen, 1)) \n",
    "\n",
    "        # Use this line to include all input features\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], lanein[idx], normin[idx], cities), axis=1)    \n",
    "\n",
    "        # Lane only\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], lanein[idx], normin[idx]), axis=1) \n",
    "\n",
    "        # Only include cities\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], cities), axis=1)     \n",
    "\n",
    "        # Only include pos/vel\n",
    "        inp_tens = np.concatenate((pin[idx], vin[idx]), axis=1)\n",
    "        \n",
    "#         inp_tens = np.concatenate((pin, vin), axis=2)\n",
    "\n",
    "        # All output features\n",
    "#             out_tens = np.concatenate((pout[idx], vout[idx], laneout[idx], normout[idx]), axis=1)\n",
    "        # Only include output position and velocity\n",
    "#             out_tens = np.concatenate((pout[idx], vout[idx]), axis=1)  \n",
    "\n",
    "        out_tens = pout[idx]\n",
    "#         out_tens = pout\n",
    "    \n",
    "        inp.append(inp_tens)\n",
    "        out.append(out_tens)\n",
    " \n",
    "\n",
    "    inp = torch.FloatTensor(inp)\n",
    "    out = torch.FloatTensor(out)\n",
    "    return [inp, out, scene_idxs, agent_idxs, city_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_val(batch):\n",
    "    \"\"\" \n",
    "    Custom collate_fn for validation dataset. The validation data do not contain output values.   \n",
    "    \"\"\"   \n",
    "    inp = []\n",
    "    scene_idxs = []\n",
    "    agent_idxs = []\n",
    "    city_ids = []\n",
    "    \n",
    "    for scene in batch:\n",
    "        # Get the target agent id\n",
    "        agent_id = scene[AGENT_ID]        \n",
    "        # Get the matrix of all agents\n",
    "        track_id = scene[TRACK_ID]        \n",
    "        # Get the location of the target agent in the matrix\n",
    "        idx = np.nonzero(track_id[:, 0] == agent_id)[0][0]\n",
    "        \n",
    "        inlen = scene[P_IN].shape[1]\n",
    "        \n",
    "        # Aliases of scene variables for convenience\n",
    "        pin, vin = scene[P_IN], scene[V_IN]\n",
    "        lanein, normin = scene[LANE_IN], scene[NORM_IN]\n",
    "        num_agents = scene[P_IN].shape[0]\n",
    "        \n",
    "        if scene[CITY] == MIA:\n",
    "            cities = np.zeros((inlen, 1)) \n",
    "        else:\n",
    "            cities = np.ones((inlen, 1)) \n",
    "        # All\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], lanein[idx], normin[idx], cities), axis=1)\n",
    "        # Lane only\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], lanein[idx], normin[idx]), axis=1)\n",
    "        # Cities\n",
    "#             inp_tens = np.concatenate((pin[idx], vin[idx], cities), axis=1)  \n",
    "        # Pos/vel\n",
    "        inp_tens = np.concatenate((pin[idx], vin[idx]), axis=1) \n",
    "\n",
    "#         inp_tens = np.concatenate((pin, vin), axis=2)  \n",
    "        \n",
    "        inp.append(inp_tens)        \n",
    "        scene_idxs.append(scene[SCENE_IDX])\n",
    "        agent_idxs.append(idx)\n",
    "        city_ids.append(CITY_MAP[scene[CITY]])        \n",
    "        \n",
    "    inp = torch.FloatTensor(inp)    \n",
    "    return [inp, scene_idxs, agent_idxs, city_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliaze datasets and loaders\n",
    "\n",
    "train_dataset = ArgoverseDataset(train_files)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, \n",
    "                                           shuffle=True, collate_fn=collate_train_test, \n",
    "                                           num_workers=N_WORKERS)\n",
    "test_dataset = ArgoverseDataset(test_files)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, \n",
    "                                          shuffle=False, collate_fn=collate_train_test, \n",
    "                                          num_workers=N_WORKERS)\n",
    "val_dataset = ArgoverseDataset(val_files)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE_VAL, \n",
    "                                         shuffle=False, collate_fn=collate_val,\n",
    "                                         num_workers=N_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 19, 4])\n",
      "torch.Size([64, 30, 2])\n"
     ]
    }
   ],
   "source": [
    "# Look at one data sample      \n",
    "for _, (data, target, agent_idxs, scene_idxs, cities) in enumerate(train_loader):\n",
    "    print(data.shape)\n",
    "    print(target.shape) \n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 19, 4])\n"
     ]
    }
   ],
   "source": [
    "# Look at one data sample      \n",
    "for _, (data, agent_idxs, scene_idxs, masks) in enumerate(val_loader):\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # Set the model into training mode\n",
    "    model.train()    \n",
    "    \n",
    "    # Define the loss function.\n",
    "#     criterion = torch.nn.MSELoss(reduction='mean')\n",
    "    criterion = torch.nn.SmoothL1Loss(reduction='mean')\n",
    "\n",
    "    total_loss = 0    \n",
    "    for i in range(epoch):\n",
    "\n",
    "        iterator = tqdm.notebook.tqdm(train_loader, total=int(len(train_loader)))\n",
    "        for _, batch in enumerate(iterator):\n",
    "            data, target, scene_idxs, agent_idxs, masks = batch\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = torch.sqrt(criterion(out, target))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform backpropagation\n",
    "            loss.backward()          \n",
    "            \n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the progress bar for tqdm\n",
    "            iterator.set_postfix(train_loss=loss.item(), rmse=torch.sqrt(nn.functional.mse_loss(out, target)).item())\n",
    "            \n",
    "    return (total_loss * BATCH_SIZE_TRAIN) / len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()    \n",
    "#     criterion = torch.nn.MSELoss(reduction='mean')    \n",
    "    criterion = torch.nn.SmoothL1Loss(reduction='mean')\n",
    "\n",
    "    iterator = tqdm.notebook.tqdm(test_loader, total=int(len(test_loader)))\n",
    "    total_loss = 0\n",
    "    \n",
    "    for _, batch in enumerate(iterator):\n",
    "        data, target, scene_idxs, agent_idxs, masks = batch\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            loss = torch.sqrt(criterion(out, target))        \n",
    "            \n",
    "            iterator.set_postfix(test_loss=loss.item(), rmse=torch.sqrt(nn.functional.mse_loss(out, target)).item())\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "\n",
    "        \n",
    "    return (total_loss * BATCH_SIZE_TEST) / len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, device, train_loader, test_loader, optimizer, NUM_EPOCH):\n",
    "    for t in range(1, NUM_EPOCH + 1):\n",
    "        train_loss = train(model, device, train_loader, optimizer, 1)\n",
    "        test_loss = test(model, device, test_loader)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        print(f'Epoch {t}: train_loss = {train_loss}, test_loss = {test_loss}')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, val_loader, path):\n",
    "    \"\"\"\n",
    "    path: path to csv file to write predictions\n",
    "    \"\"\"\n",
    "    model.eval()   \n",
    "    \n",
    "    # Prep the output file\n",
    "    with open(PREDICTION_PATH, \"w\") as csv_file:\n",
    "        # Clear the csv file before appending data to it\n",
    "        csv_file.truncate()\n",
    "        # Write the header to the csv file\n",
    "        csv_file.writelines(CSV_HEADER)    \n",
    "    \n",
    "    # Make predictions\n",
    "    with open(path, \"a\") as pred_file:        \n",
    "        iterator = tqdm.notebook.tqdm(val_loader, total=int(len(val_loader)))\n",
    "        \n",
    "        for _, batch in enumerate(iterator):\n",
    "            data, scene_idxs, agent_idxs, masks = batch\n",
    "            data = data.to(device) \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "                # Convert the Tensor from GPU -> CPU -> NumPy array\n",
    "                np_out = output.cpu().detach().numpy()\n",
    "                \n",
    "                # Store only the predictions for the target agent and keep the positions, not the velocities\n",
    "                batch_size = np_out.shape[0]\n",
    "                \n",
    "                pred = np.zeros((batch_size, 60))\n",
    "                # The output should be a (batch size, time steps, num features out) tensor \n",
    "                # where the first two features are the input position and the output position\n",
    "                for i in range(batch_size):\n",
    "                    pred[i] = np_out[i, :, :2].flatten()                   \n",
    "\n",
    "                # Form comma-separated string\n",
    "                s = []\n",
    "                for i in range(pred.shape[0]):\n",
    "                    s.append(','.join([str(scene_idxs[i])] + [str(v) for v in pred[i]]) + '\\n')\n",
    "\n",
    "                # Write data to file\n",
    "                pred_file.writelines(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ArgoNet(torch.nn.Module):\n",
    "#     \"\"\"\n",
    "#     Neural Network class - CNN with 1 conv and 1 linear layer\n",
    "#     \"\"\"\n",
    "#     def __init__(self, device):\n",
    "#         super(ArgoNet, self).__init__() \n",
    "        \n",
    "#         self.device = device \n",
    "#         self.hid = 12\n",
    "#         self.conv = nn.Sequential(\n",
    "#             nn.Conv1d(IN_LEN, self.hid, 1),\n",
    "#             nn.SELU()\n",
    "#         )\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(self.hid * N_FEAT_IN, OUT_LEN * N_FEAT_OUT),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         x = x.view(x.shape[0], self.hid * N_FEAT_IN)\n",
    "#         x = self.fc(x)\n",
    "#         x = x.view(x.shape[0], OUT_LEN, N_FEAT_OUT)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Network class - linear regression\n",
    "    \"\"\"\n",
    "    def __init__(self, device):\n",
    "        super(ArgoNet, self).__init__()         \n",
    "        self.device = device        \n",
    "        self.fc = nn.Linear(NUM_AGENTS * IN_LEN * N_FEAT_IN, 1 * OUT_LEN * N_FEAT_OUT)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # flatten result\n",
    "        x = self.fc(x)    \n",
    "        print(self.fc.weight.shape)\n",
    "        raise ValueError\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ArgoNet(torch.nn.Module):\n",
    "#     \"\"\"\n",
    "#     Neural Network class - CNN with 1 conv and 2 linear layers\n",
    "#     \"\"\"\n",
    "#     def __init__(self, device):\n",
    "#         super(ArgoNet, self).__init__() \n",
    "        \n",
    "#         self.device = device \n",
    "#         self.h1 = 8\n",
    "#         self.h2 = 64\n",
    "#         self.conv = nn.Sequential(\n",
    "#             nn.Conv1d(IN_LEN, self.h1, 1),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(self.h1 * N_FEAT_IN, self.h2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(self.h2, OUT_LEN * N_FEAT_OUT)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         x = x.view(x.shape[0], self.h1 * N_FEAT_IN)\n",
    "#         x = self.fc(x)\n",
    "#         x = x.view(x.shape[0], OUT_LEN, 2)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ArgoNet(torch.nn.Module):\n",
    "#     \"\"\"\n",
    "#     Neural Network class - CNN with multiple conv\n",
    "#     \"\"\"\n",
    "#     def __init__(self, device):\n",
    "#         super(ArgoNet, self).__init__() \n",
    "        \n",
    "#         self.device = device \n",
    "#         self.hidden_size = IN_LEN * 4\n",
    "#         self.outch1 = IN_LEN * 4\n",
    "#         self.outch2 = OUT_LEN\n",
    "#         self.conv = nn.Sequential(\n",
    "#             nn.Conv1d(IN_LEN, self.outch1, 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv1d(self.outch1, self.outch2, 1),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "#         self.fc = nn.Linear(self.outch2 * N_FEAT_IN, OUT_LEN * 2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv(x)\n",
    "# #         print(x.shape)\n",
    "# #         raise ValueError\n",
    "#         x = x.view(x.shape[0], self.hidden_size * N_FEAT_OUT)\n",
    "#         x = self.fc(x)\n",
    "#         x = x.view(x.shape[0], OUT_LEN, 2)\n",
    "# #         print(x.shape)\n",
    "# #         raise ValueError\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to save and reload a model\n",
    "MODEL_STATE = 'model_state_dict'\n",
    "OPTIMIZER_STATE = 'optimizer_state_dict'\n",
    "EPOCH_STATE = 'epoch'\n",
    "LOSS_STATE = 'loss'\n",
    "BATCH_STATE = 'batch'\n",
    "\n",
    "def save_model(path, model_state_dict, optimizer_state_dict, epoch, loss, batch):\n",
    "    to_save = {\n",
    "        MODEL_STATE: model_state_dict,\n",
    "        OPTIMIZER_STATE: optimizer_state_dict,\n",
    "        EPOCH_STATE: epoch,\n",
    "        LOSS_STATE: loss,\n",
    "        BATCH_STATE: batch\n",
    "    }\n",
    "    torch.save(to_save, path)\n",
    "    \n",
    "def load_model(path, model_to_load, optimizer_to_load):\n",
    "    checkpoint = torch.load(path)\n",
    "    model_to_load.load_state_dict(checkpoint[MODEL_STATE])\n",
    "    optimizer_to_load.load_state_dict(checkpoint[OPTIMIZER_STATE])\n",
    "    return checkpoint[EPOCH_STATE], checkpoint[LOSS_STATE], checkpoint[BATCH_STATE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters is 4620\n"
     ]
    }
   ],
   "source": [
    "model = ArgoNet(DEVICE).to(DEVICE)\n",
    "learning_rate = 1e-2\n",
    "weight_decay = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())  # Best optimizer so far\n",
    "# optimizer = torch.optim.AdamW(model.parameters())  # Can't decrease training loss below 4\n",
    "\n",
    "# optimizer = torch.optim.RMSprop(model.parameters())  # Doesn't converge w/o tuning\n",
    "# momentum = 0.9\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)  # Doesn't converge w/o tuning\n",
    "# optimizer = torch.optim.Adagrad(model.parameters())  # Better than others, not as good as Adam\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())   \n",
    "print(f\"Number of model parameters is {num_params}\")\n",
    "NUM_EPOCH = 1\n",
    "\n",
    "# used for visualizing the loss\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use these two lines to save a model\n",
    "# save_model('conv_hid12_adam_epoch2_selu_batch1.tar', model.state_dict(), optimizer.state_dict(), NUM_EPOCH, \n",
    "#            (train_losses[-1], test_losses[-1]), BATCH_SIZE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload a model\n",
    "# model = ArgoNet(DEVICE).to(DEVICE)\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "# load_model('conv_3_adam_epoch_posvel_outpos_only_wd_001.tar', model, optimizer)\n",
    "# train_losses.clear()\n",
    "# test_losses.clear()\n",
    "# num_params = sum(p.numel() for p in model.parameters())   \n",
    "# print(f\"Number of model parameters is {num_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b168292e8a4914bff71954c641b9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2575.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 76])\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-9b4c78cb5419>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_EPOCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-fa5b1a031a3c>\u001b[0m in \u001b[0;36mtrain_test\u001b[1;34m(model, device, train_loader, test_loader, optimizer, NUM_EPOCH)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_EPOCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_EPOCH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-23335949938b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-97ce4ad8e88a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_test(model, DEVICE, train_loader, test_loader, optimizer, NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df596d90c66d4e4dacd42000c9079c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=164753.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ccb57c65074231af637c6163056046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=41189.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: train_loss = 6.41181386300975, test_loss = 3.299621803233668\n"
     ]
    }
   ],
   "source": [
    "train_test(model, DEVICE, train_loader, test_loader, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99882bc2c044cd7a2a60c47a9270bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=164753.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3f9b9c22e847c3a42f8137050a9dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=41189.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: train_loss = 6.358699650818349, test_loss = 5.908405622638564\n"
     ]
    }
   ],
   "source": [
    "train_test(model, DEVICE, train_loader, test_loader, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409827819507454e836587d44574eb18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=164753.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bc3760f02640708f3a12117a8720e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=41189.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: train_loss = 6.401098176951562, test_loss = 5.353363151407204\n"
     ]
    }
   ],
   "source": [
    "train_test(model, DEVICE, train_loader, test_loader, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7663243c3e834d82a20c3e284030ac1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=164753.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f61a2edb35c493fb0658358c74898d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=41189.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: train_loss = 6.392980042618332, test_loss = 4.450427855534854\n"
     ]
    }
   ],
   "source": [
    "train_test(model, DEVICE, train_loader, test_loader, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b81a63b23143eaa434227e3bdd0596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=164753.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72968255ab5145d5a291fafa2b656f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=41189.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: train_loss = 6.399976239997151, test_loss = 4.661777555813743\n"
     ]
    }
   ],
   "source": [
    "train_test(model, DEVICE, train_loader, test_loader, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79eb43d13f1746c29929513bf73f05b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validate(model, DEVICE, val_loader, PREDICTION_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(losses):\n",
    "    \"\"\"\n",
    "    Plots the losses over each training iteration. \n",
    "    Assumes that each element of the 'losses' list corresponds to the loss after each batch of train()\n",
    "    \"\"\"\n",
    "    t_iter = np.arange(1, len(losses) + 1, 1, dtype=int)\n",
    "    ax = sns.scatterplot(x=t_iter, y=losses, alpha=0.5)    \n",
    "    ax.set_xlabel('Batch iteration number')\n",
    "    ax.set_ylabel('Root-mean-square loss')\n",
    "    ax.set_title('Batch Iteration vs. Root-Mean-Square Loss')\n",
    "    plt.savefig('lossViter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_loss(train_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, device, loader):\n",
    "    \"\"\"\n",
    "    Compares some randomly selected data samples to the model's predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of data\n",
    "    _, (inp, out, scene_idxs, agent_idxs, masks) = next(enumerate(loader))\n",
    "    \n",
    "    # Move tensors to chosen device\n",
    "    inp, out = inp.to(device), out.to(device)\n",
    "    \n",
    "    # Sample number\n",
    "    i = 0\n",
    "    \n",
    "    # Scene idx\n",
    "    scene_idx = scene_idxs[i]\n",
    "        \n",
    "    # Get contiguous arrays of the ground truth output positions\n",
    "    truth = target[i].cpu().detach().numpy()\n",
    "    x = truth[:, 0]\n",
    "    y = truth[:, 1] \n",
    "        \n",
    "    # Get contiguous arrays of the prediction output positions\n",
    "    output = model(inp)    \n",
    "    pred = output[i].cpu().detach().numpy()\n",
    "    xh = pred[:, 0]\n",
    "    yh = pred[:, 0]    \n",
    "    \n",
    "    # Plot the ground truth and prediction positions\n",
    "    fig, (ax) = plt.subplots(nrows=1, ncols=1, figsize=(3, 3))\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_title('Scene ' + str(scene_idx))\n",
    "    ax.scatter(x, y, label='Ground Truth')\n",
    "    ax.scatter(xh, yh, label='Prediction')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(model, DEVICE, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
